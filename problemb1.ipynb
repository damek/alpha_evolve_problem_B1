{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the step function, the integral, and the autoconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Step function representation:\n",
    "# The step function f is implicitly defined by:\n",
    "# - heights: a 1D tensor of P non-negative values h_i.\n",
    "# - P: number of pieces.\n",
    "# - interval_range: a tuple (x_min, x_max), e.g., (-0.25, 0.25).\n",
    "# - delta_x: width of each piece, (x_max - x_min) / P.\n",
    "# - x_coords: tensor of starting x-coordinates for each piece.\n",
    "# For optimization, 'heights' would be your learnable parameters.\n",
    "#\n",
    "# Example of how you might define these:\n",
    "# P = 600\n",
    "# interval_range = (-0.25, 0.25)\n",
    "# heights = torch.rand(P, dtype=torch.float64, requires_grad=True) # example heights\n",
    "# delta_x = (interval_range[1] - interval_range[0]) / P\n",
    "# x_min = interval_range[0]\n",
    "\n",
    "def compute_integral_of_step_function(heights: torch.Tensor, delta_x: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the integral of the step function f(x)dx.\n",
    "    f(x) is defined by `heights` h_i over pieces of width `delta_x`.\n",
    "    Integral = delta_x * sum(h_i).\n",
    "    \"\"\"\n",
    "    if not torch.all(heights >= 0):\n",
    "        # print(\"warning: heights should be non-negative for the problem context.\")\n",
    "        # depending on your optimization strategy, you might enforce this elsewhere (e.g. h_i = relu(alpha_i))\n",
    "        pass # up to you how strict to be here, problem says \"non-negative f\"\n",
    "    return delta_x * torch.sum(heights)\n",
    "\n",
    "def compute_autoconvolution_values(heights: torch.Tensor, delta_x: float, P: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the values of the autoconvolution (f*f)(t) at the knot points.\n",
    "    (f*f)(t) is piecewise linear. Max value occurs at one of these knots.\n",
    "    Knots are t_m = 2*x_min + m*delta_x for m = 0, ..., 2P.\n",
    "    Values are [0, delta_x * (H*H)_0, ..., delta_x * (H*H)_{2P-2}, 0].\n",
    "    (H*H) is the discrete convolution of the height sequence H.\n",
    "    \"\"\"\n",
    "    # Ensure heights is 1D\n",
    "    if heights.ndim != 1 or heights.shape[0] != P:\n",
    "        raise ValueError(f\"heights tensor must be 1D with length P={P}. Got shape {heights.shape}\")\n",
    "\n",
    "    # Reshape heights for conv1d: (batch_size, C_in, L_in)\n",
    "    # batch_size=1, C_in=1\n",
    "    h_signal = heights.view(1, 1, P)\n",
    "    \n",
    "    # The kernel for conv1d to compute (H*H) should be H flipped.\n",
    "    # weight for conv1d: (C_out, C_in/groups, L_kernel)\n",
    "    # C_out=1, C_in/groups=1\n",
    "    h_kernel_flipped = torch.flip(heights, dims=[0]).view(1, 1, P)\n",
    "\n",
    "    # Compute H*H using conv1d. Padding P-1 results in output length 2P-1.\n",
    "    # These are (H*H)_0, ..., (H*H)_{2P-2}\n",
    "    conv_result = F.conv1d(h_signal, h_kernel_flipped, padding=P-1).squeeze()\n",
    "    \n",
    "    # Scale by delta_x\n",
    "    conv_scaled = delta_x * conv_result\n",
    "    \n",
    "    # Add zeros for (f*f)(t_0) and (f*f)(t_{2P})\n",
    "    zero = torch.tensor([0.0], device=heights.device, dtype=heights.dtype)\n",
    "    autoconvolution_knot_values = torch.cat([zero, conv_scaled, zero])\n",
    "    \n",
    "    return autoconvolution_knot_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the step function and the autoconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Function Details (P=600) ---\n",
      "Integral of f(x): 0.245511\n",
      "Max value of autoconvolution (f*f)(t): 0.122913\n",
      "Ratio max(f*f) / (integral(f))^2: 2.039187\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# script assumes 'compute_integral_of_step_function' and 'compute_autoconvolution_values'\n",
    "# (from your previous code block) are already defined and executable in the notebook.\n",
    "\n",
    "#@title Imports and Plotting Setup\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- plotting functions ---\n",
    "def plot_rendered_step_function(heights_numpy: np.ndarray, interval: tuple[float, float], title=\"\"):\n",
    "    \"\"\"plots a step function f(x) cleanly using plt.step.\"\"\"\n",
    "    P = len(heights_numpy)\n",
    "    x_min, x_max = interval\n",
    "    \n",
    "    step_edges = np.linspace(x_min, x_max, P + 1, dtype=float) # ensure float for plotting\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.step(step_edges[:-1], heights_numpy, where='post', color='blue', linewidth=1.5)\n",
    "    \n",
    "    plt.axhline(0, color='black', linewidth=0.5) # reference line at y=0\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"f(x)\")\n",
    "    plt.title(title)\n",
    "    \n",
    "    # dynamic axis limits\n",
    "    x_padding = 0.05 * (x_max - x_min) if (x_max - x_min) > 0 else 0.05\n",
    "    plt.xlim([x_min - x_padding, x_max + x_padding])\n",
    "    \n",
    "    if P > 0:\n",
    "        max_h = np.max(heights_numpy)\n",
    "        min_h = np.min(heights_numpy) # relevant if heights could be negative\n",
    "        if max_h > 0: # typical case for non-negative heights\n",
    "            plt.ylim([-0.1 * max_h, max_h * 1.2])\n",
    "        elif max_h == 0 and min_h == 0 : # all zero heights\n",
    "            plt.ylim([-0.5, 0.5])\n",
    "        else: # other cases (e.g. all negative, not expected here)\n",
    "            plt.ylim([min_h - 0.1*abs(min_h), max_h + 0.1*abs(max_h)])\n",
    "\n",
    "    else: # P=0, no data\n",
    "        plt.ylim([-0.5, 1.0]) \n",
    "        \n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_rendered_convolution(t_values_numpy: np.ndarray, conv_values_numpy: np.ndarray, title=\"\"):\n",
    "    \"\"\"plots a piecewise linear function, e.g., the autoconvolution f*f(t).\"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(t_values_numpy, conv_values_numpy, marker='o', linestyle='-', color='green', markersize=3, linewidth=1.5)\n",
    "    \n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"f*f(t)\")\n",
    "    plt.title(title)\n",
    "    \n",
    "    if len(t_values_numpy) > 0:\n",
    "        t_min, t_max = t_values_numpy[0], t_values_numpy[-1]\n",
    "        t_padding = 0.05 * (t_max - t_min) if (t_max - t_min) > 0 else 0.05\n",
    "        plt.xlim([t_min - t_padding, t_max + t_padding])\n",
    "        \n",
    "        max_conv = np.max(conv_values_numpy)\n",
    "        min_conv = np.min(conv_values_numpy)\n",
    "        # autoconvolution of non-negative f(x) is non-negative\n",
    "        if max_conv > 0:\n",
    "            plt.ylim([-0.1 * max_conv, max_conv * 1.2])\n",
    "        else: # all zero (or P=0 for f(x))\n",
    "            plt.ylim([-0.5, 0.5])\n",
    "    else: # no data\n",
    "        plt.xlim([-0.55, 0.55]) # default based on expected autoconv range\n",
    "        plt.ylim([-0.1, 1.0])\n",
    "        \n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# --- main script logic ---\n",
    "P_val = 600  # number of pieces for the step function\n",
    "f_interval = (-0.25, 0.25) # interval for f(x)\n",
    "\n",
    "f_x_min, f_x_max = f_interval\n",
    "f_delta_x = (f_x_max - f_x_min) / P_val\n",
    "\n",
    "# 1. sample random heights (non-negative)\n",
    "# using float64 for precision, requires_grad=False for plotting/evaluation only\n",
    "height_values = torch.rand(P_val, dtype=torch.float64) \n",
    "# for more structured/sparse functions, you could try:\n",
    "# height_values = torch.abs(torch.randn(P_val, dtype=torch.float64)) * (torch.rand(P_val, dtype=torch.float64) > 0.7).double()\n",
    "\n",
    "\n",
    "# 2. compute integral of f(x)\n",
    "integral_value = compute_integral_of_step_function(height_values, f_delta_x)\n",
    "\n",
    "# 3. compute autoconvolution (f*f)(t) knot values\n",
    "# (2*P_val + 1) values for t_m from 2*f_x_min to 2*f_x_max\n",
    "autoconv_knot_vals = compute_autoconvolution_values(height_values, f_delta_x, P_val)\n",
    "max_autoconv_value = torch.max(autoconv_knot_vals)\n",
    "\n",
    "# 4. calculate the ratio for C1 estimate\n",
    "# (max f*f(t)) / (integral f(x) dx)^2\n",
    "if integral_value.item() == 0:\n",
    "    c1_ratio = float('inf') if max_autoconv_value.item() > 0 else 0.0 # handle division by zero\n",
    "else:\n",
    "    c1_ratio = max_autoconv_value / (integral_value**2)\n",
    "\n",
    "print(f\"--- Function Details (P={P_val}) ---\")\n",
    "# print(f\"Heights (h_i, first 10): {height_values.numpy()[:10]}\") # uncomment if you want to see heights\n",
    "print(f\"Integral of f(x): {integral_value.item():.6f}\")\n",
    "print(f\"Max value of autoconvolution (f*f)(t): {max_autoconv_value.item():.6f}\")\n",
    "print(f\"Ratio max(f*f) / (integral(f))^2: {c1_ratio.item():.6f}\")\n",
    "\n",
    "\n",
    "# 5. plotting\n",
    "# plot f(x)\n",
    "plot_rendered_step_function(height_values.numpy(), f_interval, title=f\"Random Step Function f(x) (P={P_val})\")\n",
    "\n",
    "# plot f*f(t)\n",
    "# autoconvolution is defined on [2*f_x_min, 2*f_x_max]\n",
    "conv_t_knots = np.linspace(2 * f_x_min, 2 * f_x_max, 2 * P_val + 1, dtype=float)\n",
    "plot_rendered_convolution(conv_t_knots, autoconv_knot_vals.numpy(), title=f\"Autoconvolution f*f(t) (P={P_val})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection onto the simplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w tensor([32.3333, 33.3333, 34.3333]) sum(w) tensor(100.0000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def projection_simplex_pytorch(v: torch.Tensor, z: float = 1.0) -> torch.Tensor:\n",
    "    n_features = v.shape[0]\n",
    "    if n_features == 0:\n",
    "        return torch.empty_like(v)\n",
    "    u, _ = torch.sort(v, descending=True)\n",
    "    cssv_minus_z = torch.cumsum(u, dim=0) - z\n",
    "    ind = torch.arange(1, n_features + 1, device=v.device) \n",
    "    cond = u - cssv_minus_z / ind > 0\n",
    "    true_indices = torch.where(cond)[0]\n",
    "    rho_idx = true_indices[-1] \n",
    "    rho = ind[rho_idx] \n",
    "    theta = cssv_minus_z[rho_idx] / rho \n",
    "    w = torch.clamp(v - theta, min=0.0)\n",
    "    return w\n",
    "\n",
    "# test the function\n",
    "v = torch.tensor([1.0, 2.0, 3.0])\n",
    "z = 100\n",
    "w = projection_simplex_pytorch(v, z)\n",
    "print(\"w\", w, \"sum(w)\", sum(w))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up parameters, loss function, and compute the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.0038365431176195\n",
      "height_params.grad tensor([0.0025, 0.0037, 0.0043, 0.0018, 0.0048, 0.0030, 0.0041, 0.0038, 0.0021,\n",
      "        0.0032, 0.0046, 0.0028, 0.0026, 0.0028, 0.0034, 0.0045, 0.0027, 0.0033,\n",
      "        0.0040, 0.0017, 0.0034, 0.0048, 0.0042, 0.0042, 0.0027, 0.0042, 0.0045,\n",
      "        0.0036, 0.0035, 0.0044, 0.0022, 0.0031, 0.0039, 0.0037, 0.0044, 0.0039,\n",
      "        0.0037, 0.0023, 0.0041, 0.0029, 0.0034, 0.0028, 0.0041, 0.0037, 0.0020,\n",
      "        0.0017, 0.0050, 0.0040, 0.0026, 0.0024, 0.0046, 0.0041, 0.0037, 0.0035,\n",
      "        0.0047, 0.0031, 0.0050, 0.0029, 0.0039, 0.0023, 0.0046, 0.0018, 0.0020,\n",
      "        0.0027, 0.0031, 0.0031, 0.0038, 0.0032, 0.0020, 0.0027, 0.0025, 0.0047,\n",
      "        0.0045, 0.0043, 0.0046, 0.0031, 0.0019, 0.0026, 0.0043, 0.0035, 0.0034,\n",
      "        0.0039, 0.0020, 0.0035, 0.0022, 0.0035, 0.0023, 0.0032, 0.0046, 0.0017,\n",
      "        0.0035, 0.0023, 0.0041, 0.0019, 0.0039, 0.0017, 0.0025, 0.0046, 0.0045,\n",
      "        0.0042, 0.0017, 0.0044, 0.0030, 0.0037, 0.0042, 0.0036, 0.0041, 0.0027,\n",
      "        0.0021, 0.0048, 0.0033, 0.0035, 0.0034, 0.0044, 0.0045, 0.0028, 0.0048,\n",
      "        0.0039, 0.0027, 0.0039, 0.0036, 0.0025, 0.0029, 0.0017, 0.0037, 0.0030,\n",
      "        0.0040, 0.0026, 0.0035, 0.0035, 0.0033, 0.0048, 0.0050, 0.0019, 0.0040,\n",
      "        0.0045, 0.0048, 0.0023, 0.0043, 0.0017, 0.0043, 0.0044, 0.0035, 0.0049,\n",
      "        0.0032, 0.0046, 0.0045, 0.0028, 0.0044, 0.0038, 0.0044, 0.0018, 0.0043,\n",
      "        0.0023, 0.0043, 0.0043, 0.0028, 0.0033, 0.0045, 0.0048, 0.0037, 0.0026,\n",
      "        0.0043, 0.0036, 0.0033, 0.0044, 0.0042, 0.0041, 0.0031, 0.0030, 0.0017,\n",
      "        0.0043, 0.0028, 0.0047, 0.0029, 0.0050, 0.0018, 0.0018, 0.0025, 0.0044,\n",
      "        0.0049, 0.0031, 0.0045, 0.0029, 0.0037, 0.0032, 0.0022, 0.0022, 0.0039,\n",
      "        0.0032, 0.0024, 0.0034, 0.0035, 0.0026, 0.0046, 0.0020, 0.0031, 0.0027,\n",
      "        0.0036, 0.0027, 0.0028, 0.0022, 0.0028, 0.0021, 0.0021, 0.0050, 0.0045,\n",
      "        0.0037, 0.0039, 0.0032, 0.0019, 0.0037, 0.0018, 0.0022, 0.0040, 0.0030,\n",
      "        0.0017, 0.0049, 0.0033, 0.0028, 0.0022, 0.0043, 0.0027, 0.0017, 0.0048,\n",
      "        0.0036, 0.0025, 0.0025, 0.0047, 0.0032, 0.0041, 0.0034, 0.0019, 0.0041,\n",
      "        0.0029, 0.0045, 0.0019, 0.0044, 0.0034, 0.0025, 0.0049, 0.0028, 0.0021,\n",
      "        0.0049, 0.0036, 0.0027, 0.0043, 0.0033, 0.0044, 0.0047, 0.0033, 0.0024,\n",
      "        0.0036, 0.0017, 0.0018, 0.0017, 0.0029, 0.0035, 0.0043, 0.0021, 0.0044,\n",
      "        0.0019, 0.0042, 0.0023, 0.0022, 0.0030, 0.0017, 0.0027, 0.0042, 0.0046,\n",
      "        0.0032, 0.0021, 0.0046, 0.0041, 0.0020, 0.0046, 0.0033, 0.0027, 0.0031,\n",
      "        0.0019, 0.0025, 0.0044, 0.0047, 0.0023, 0.0039, 0.0046, 0.0026, 0.0025,\n",
      "        0.0020, 0.0048, 0.0028, 0.0020, 0.0048, 0.0049, 0.0025, 0.0045, 0.0024,\n",
      "        0.0049, 0.0019, 0.0019, 0.0024, 0.0050, 0.0041, 0.0031, 0.0033, 0.0024,\n",
      "        0.0037, 0.0017, 0.0026, 0.0031, 0.0029, 0.0036, 0.0044, 0.0042, 0.0019,\n",
      "        0.0022, 0.0041, 0.0039, 0.0044, 0.0028, 0.0049, 0.0049, 0.0040, 0.0044,\n",
      "        0.0036, 0.0040, 0.0018, 0.0044, 0.0043, 0.0027, 0.0031, 0.0039, 0.0021,\n",
      "        0.0017, 0.0043, 0.0039, 0.0030, 0.0047, 0.0040, 0.0022, 0.0049, 0.0030,\n",
      "        0.0027, 0.0022, 0.0021, 0.0018, 0.0031, 0.0042, 0.0023, 0.0045, 0.0020,\n",
      "        0.0049, 0.0050, 0.0024, 0.0024, 0.0027, 0.0031, 0.0031, 0.0033, 0.0041,\n",
      "        0.0044, 0.0044, 0.0024, 0.0047, 0.0027, 0.0021, 0.0037, 0.0045, 0.0036,\n",
      "        0.0035, 0.0034, 0.0046, 0.0044, 0.0041, 0.0049, 0.0042, 0.0029, 0.0017,\n",
      "        0.0050, 0.0024, 0.0046, 0.0026, 0.0036, 0.0018, 0.0030, 0.0018, 0.0039,\n",
      "        0.0041, 0.0045, 0.0024, 0.0040, 0.0018, 0.0018, 0.0034, 0.0042, 0.0024,\n",
      "        0.0038, 0.0035, 0.0044, 0.0043, 0.0036, 0.0049, 0.0024, 0.0039, 0.0023,\n",
      "        0.0031, 0.0029, 0.0018, 0.0044, 0.0038, 0.0040, 0.0045, 0.0044, 0.0027,\n",
      "        0.0018, 0.0048, 0.0032, 0.0032, 0.0030, 0.0033, 0.0027, 0.0035, 0.0047,\n",
      "        0.0037, 0.0026, 0.0027, 0.0022, 0.0043, 0.0033, 0.0032, 0.0032, 0.0028,\n",
      "        0.0017, 0.0023, 0.0043, 0.0032, 0.0026, 0.0032, 0.0024, 0.0024, 0.0017,\n",
      "        0.0028, 0.0048, 0.0022, 0.0049, 0.0031, 0.0046, 0.0021, 0.0020, 0.0039,\n",
      "        0.0040, 0.0029, 0.0050, 0.0027, 0.0049, 0.0020, 0.0048, 0.0040, 0.0021,\n",
      "        0.0022, 0.0017, 0.0042, 0.0039, 0.0034, 0.0027, 0.0029, 0.0027, 0.0048,\n",
      "        0.0045, 0.0045, 0.0028, 0.0022, 0.0049, 0.0028, 0.0025, 0.0041, 0.0020,\n",
      "        0.0049, 0.0050, 0.0031, 0.0023, 0.0032, 0.0048, 0.0032, 0.0033, 0.0033,\n",
      "        0.0030, 0.0046, 0.0031, 0.0040, 0.0027, 0.0043, 0.0030, 0.0040, 0.0021,\n",
      "        0.0047, 0.0017, 0.0023, 0.0025, 0.0039, 0.0049, 0.0029, 0.0039, 0.0024,\n",
      "        0.0030, 0.0024, 0.0034, 0.0019, 0.0035, 0.0027, 0.0030, 0.0023, 0.0033,\n",
      "        0.0030, 0.0022, 0.0038, 0.0034, 0.0024, 0.0031, 0.0034, 0.0035, 0.0022,\n",
      "        0.0040, 0.0045, 0.0045, 0.0022, 0.0024, 0.0019, 0.0041, 0.0023, 0.0018,\n",
      "        0.0024, 0.0030, 0.0032, 0.0048, 0.0030, 0.0043, 0.0024, 0.0020, 0.0022,\n",
      "        0.0043, 0.0026, 0.0029, 0.0038, 0.0039, 0.0048, 0.0026, 0.0045, 0.0018,\n",
      "        0.0022, 0.0028, 0.0046, 0.0022, 0.0045, 0.0045, 0.0028, 0.0038, 0.0034,\n",
      "        0.0036, 0.0046, 0.0030, 0.0036, 0.0017, 0.0028, 0.0047, 0.0033, 0.0028,\n",
      "        0.0031, 0.0019, 0.0031, 0.0022, 0.0035, 0.0043, 0.0050, 0.0029, 0.0026,\n",
      "        0.0037, 0.0017, 0.0036, 0.0025, 0.0043, 0.0033, 0.0029, 0.0037, 0.0022,\n",
      "        0.0028, 0.0041, 0.0042, 0.0047, 0.0027, 0.0047, 0.0034, 0.0030, 0.0021,\n",
      "        0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Setting function parameters\n",
    "P_val = 600  # number of pieces for the step function\n",
    "f_interval = (-0.25, 0.25) # interval for f(x)\n",
    "\n",
    "f_x_min, f_x_max = f_interval\n",
    "f_delta_x = (f_x_max - f_x_min) / P_val\n",
    "\n",
    "# Define optimization variable\n",
    "height_params = torch.rand(P_val, dtype=torch.float64)\n",
    "height_params.requires_grad = True\n",
    "\n",
    "def loss_fn(): \n",
    "    max_f_conv_f_values_at_knots = compute_autoconvolution_values(height_params, f_delta_x, P_val)\n",
    "    return max_f_conv_f_values_at_knots.max()\n",
    "\n",
    "# Project variables onto the simplex \n",
    "with torch.no_grad():\n",
    "    height_params.data = projection_simplex_pytorch(height_params.data, 2*P_val)\n",
    "\n",
    "# Compute loss and gradient\n",
    "height_params.grad = None\n",
    "loss = loss_fn()\n",
    "loss.backward()\n",
    "print(\"loss\", loss.item())\n",
    "\n",
    "print(\"height_params.grad\", height_params.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 1: (Projected) Polyak subgradient method\n",
    "\n",
    "The algorithm \n",
    "$$\n",
    "h_+ = \\mathrm{proj}_{\\Delta_{2P}}\\left(h - \\frac{L(h) - L^*}{\\| \\nabla L(h) \\|^2} \\nabla L(h)\\right)\n",
    "$$\n",
    "where $L^*$ is the target loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: loss = 1.519450, step_size = 0.233750, min_loss_found = 1.519248\n",
      "Iteration 100: loss = 1.519464, step_size = 0.168880, min_loss_found = 1.519248\n",
      "Iteration 200: loss = 1.519440, step_size = 0.134518, min_loss_found = 1.519248\n",
      "Iteration 300: loss = 1.519413, step_size = 0.138753, min_loss_found = 1.519248\n",
      "Iteration 400: loss = 1.519546, step_size = 0.163531, min_loss_found = 1.519248\n",
      "Iteration 500: loss = 1.519471, step_size = 0.207222, min_loss_found = 1.519248\n",
      "Iteration 600: loss = 1.519530, step_size = 0.181352, min_loss_found = 1.519248\n",
      "Iteration 700: loss = 1.519455, step_size = 0.160516, min_loss_found = 1.519248\n",
      "Iteration 800: loss = 1.519378, step_size = 0.242725, min_loss_found = 1.519248\n",
      "Iteration 900: loss = 1.519462, step_size = 0.171143, min_loss_found = 1.519248\n",
      "Iteration 1000: loss = 1.519345, step_size = 0.200080, min_loss_found = 1.519248\n",
      "Iteration 1100: loss = 1.519449, step_size = 0.151273, min_loss_found = 1.519248\n",
      "Iteration 1200: loss = 1.519460, step_size = 0.143361, min_loss_found = 1.519248\n",
      "Iteration 1300: loss = 1.519471, step_size = 0.140392, min_loss_found = 1.519248\n",
      "Iteration 1400: loss = 1.519507, step_size = 0.143265, min_loss_found = 1.519248\n",
      "Iteration 1500: loss = 1.519534, step_size = 0.243815, min_loss_found = 1.519248\n",
      "Iteration 1600: loss = 1.519347, step_size = 0.158348, min_loss_found = 1.519248\n",
      "Iteration 1700: loss = 1.519375, step_size = 0.145259, min_loss_found = 1.519248\n",
      "Iteration 1800: loss = 1.519309, step_size = 0.126496, min_loss_found = 1.519248\n",
      "Iteration 1900: loss = 1.519431, step_size = 0.135821, min_loss_found = 1.519248\n",
      "Iteration 2000: loss = 1.519475, step_size = 0.239410, min_loss_found = 1.519246\n",
      "Iteration 2100: loss = 1.519441, step_size = 0.160556, min_loss_found = 1.519246\n",
      "Iteration 2200: loss = 1.519496, step_size = 0.186909, min_loss_found = 1.519246\n",
      "Iteration 2300: loss = 1.519379, step_size = 0.205622, min_loss_found = 1.519246\n",
      "Iteration 2400: loss = 1.519570, step_size = 0.245383, min_loss_found = 1.519246\n",
      "Iteration 2500: loss = 1.519317, step_size = 0.137739, min_loss_found = 1.519246\n",
      "Iteration 2600: loss = 1.519402, step_size = 0.156581, min_loss_found = 1.519246\n",
      "Iteration 2700: loss = 1.519349, step_size = 0.166113, min_loss_found = 1.519246\n",
      "Iteration 2800: loss = 1.519578, step_size = 0.154231, min_loss_found = 1.519246\n",
      "Iteration 2900: loss = 1.519412, step_size = 0.125299, min_loss_found = 1.519246\n",
      "Iteration 3000: loss = 1.519401, step_size = 0.137635, min_loss_found = 1.519246\n",
      "Iteration 3100: loss = 1.519483, step_size = 0.177249, min_loss_found = 1.519246\n",
      "Iteration 3200: loss = 1.519315, step_size = 0.235484, min_loss_found = 1.519246\n",
      "Iteration 3300: loss = 1.519526, step_size = 0.155472, min_loss_found = 1.519246\n",
      "Iteration 3400: loss = 1.519328, step_size = 0.148074, min_loss_found = 1.519246\n",
      "Iteration 3500: loss = 1.519530, step_size = 0.138857, min_loss_found = 1.519246\n",
      "Iteration 3600: loss = 1.519311, step_size = 0.158458, min_loss_found = 1.519246\n",
      "Iteration 3700: loss = 1.519432, step_size = 0.179435, min_loss_found = 1.519246\n",
      "Iteration 3800: loss = 1.519452, step_size = 0.143453, min_loss_found = 1.519246\n",
      "Iteration 3900: loss = 1.519433, step_size = 0.169430, min_loss_found = 1.519246\n",
      "Iteration 4000: loss = 1.519486, step_size = 0.141504, min_loss_found = 1.519246\n",
      "Iteration 4100: loss = 1.519372, step_size = 0.126186, min_loss_found = 1.519246\n",
      "Iteration 4200: loss = 1.519497, step_size = 0.150323, min_loss_found = 1.519246\n",
      "Iteration 4300: loss = 1.519368, step_size = 0.163233, min_loss_found = 1.519246\n",
      "Iteration 4400: loss = 1.519414, step_size = 0.140512, min_loss_found = 1.519246\n",
      "Iteration 4500: loss = 1.519384, step_size = 0.216385, min_loss_found = 1.519246\n",
      "Iteration 4600: loss = 1.519415, step_size = 0.228973, min_loss_found = 1.519246\n",
      "Iteration 4700: loss = 1.519455, step_size = 0.156587, min_loss_found = 1.519240\n",
      "Iteration 4800: loss = 1.519484, step_size = 0.158216, min_loss_found = 1.519240\n",
      "Iteration 4900: loss = 1.519442, step_size = 0.170318, min_loss_found = 1.519240\n",
      "Iteration 5000: loss = 1.519402, step_size = 0.138803, min_loss_found = 1.519240\n",
      "Iteration 5100: loss = 1.519297, step_size = 0.142325, min_loss_found = 1.519240\n",
      "Iteration 5200: loss = 1.519406, step_size = 0.135143, min_loss_found = 1.519240\n",
      "Iteration 5300: loss = 1.519458, step_size = 0.149032, min_loss_found = 1.519240\n",
      "Iteration 5400: loss = 1.519367, step_size = 0.164179, min_loss_found = 1.519240\n",
      "Iteration 5500: loss = 1.519465, step_size = 0.184382, min_loss_found = 1.519240\n",
      "Iteration 5600: loss = 1.519369, step_size = 0.212481, min_loss_found = 1.519240\n",
      "Iteration 5700: loss = 1.519528, step_size = 0.212875, min_loss_found = 1.519240\n",
      "Iteration 5800: loss = 1.519510, step_size = 0.179074, min_loss_found = 1.519240\n",
      "Iteration 5900: loss = 1.519549, step_size = 0.163736, min_loss_found = 1.519240\n",
      "Iteration 6000: loss = 1.519371, step_size = 0.162322, min_loss_found = 1.519240\n",
      "Iteration 6100: loss = 1.519492, step_size = 0.208201, min_loss_found = 1.519240\n",
      "Iteration 6200: loss = 1.519560, step_size = 0.149652, min_loss_found = 1.519240\n",
      "Iteration 6300: loss = 1.519489, step_size = 0.173809, min_loss_found = 1.519240\n",
      "Iteration 6400: loss = 1.519552, step_size = 0.156873, min_loss_found = 1.519240\n",
      "Iteration 6500: loss = 1.519315, step_size = 0.126209, min_loss_found = 1.519240\n",
      "Iteration 6600: loss = 1.519406, step_size = 0.214506, min_loss_found = 1.519240\n",
      "Iteration 6700: loss = 1.519494, step_size = 0.231290, min_loss_found = 1.519240\n",
      "Iteration 6800: loss = 1.519315, step_size = 0.211550, min_loss_found = 1.519240\n",
      "Iteration 6900: loss = 1.519419, step_size = 0.169599, min_loss_found = 1.519240\n",
      "Iteration 7000: loss = 1.519421, step_size = 0.227488, min_loss_found = 1.519240\n",
      "Iteration 7100: loss = 1.519334, step_size = 0.162411, min_loss_found = 1.519240\n",
      "Iteration 7200: loss = 1.519445, step_size = 0.175343, min_loss_found = 1.519240\n",
      "Iteration 7300: loss = 1.519317, step_size = 0.185309, min_loss_found = 1.519240\n",
      "Iteration 7400: loss = 1.519422, step_size = 0.164599, min_loss_found = 1.519240\n",
      "Iteration 7500: loss = 1.519526, step_size = 0.153769, min_loss_found = 1.519240\n",
      "Iteration 7600: loss = 1.519443, step_size = 0.168816, min_loss_found = 1.519240\n",
      "Iteration 7700: loss = 1.519370, step_size = 0.129511, min_loss_found = 1.519240\n",
      "Iteration 7800: loss = 1.519386, step_size = 0.157719, min_loss_found = 1.519240\n",
      "Iteration 7900: loss = 1.519457, step_size = 0.169685, min_loss_found = 1.519240\n",
      "Iteration 8000: loss = 1.519345, step_size = 0.167166, min_loss_found = 1.519240\n",
      "Iteration 8100: loss = 1.519474, step_size = 0.170914, min_loss_found = 1.519240\n",
      "Iteration 8200: loss = 1.519454, step_size = 0.176432, min_loss_found = 1.519237\n",
      "Iteration 8300: loss = 1.519401, step_size = 0.124305, min_loss_found = 1.519237\n",
      "Iteration 8400: loss = 1.519486, step_size = 0.176343, min_loss_found = 1.519237\n",
      "Iteration 8500: loss = 1.519539, step_size = 0.220654, min_loss_found = 1.519237\n",
      "Iteration 8600: loss = 1.519440, step_size = 0.156461, min_loss_found = 1.519237\n",
      "Iteration 8700: loss = 1.519347, step_size = 0.214824, min_loss_found = 1.519237\n",
      "Iteration 8800: loss = 1.519484, step_size = 0.150480, min_loss_found = 1.519237\n",
      "Iteration 8900: loss = 1.519439, step_size = 0.229542, min_loss_found = 1.519237\n",
      "Iteration 9000: loss = 1.519387, step_size = 0.161175, min_loss_found = 1.519237\n",
      "Iteration 9100: loss = 1.519322, step_size = 0.145611, min_loss_found = 1.519237\n",
      "Iteration 9200: loss = 1.519326, step_size = 0.152110, min_loss_found = 1.519237\n",
      "Iteration 9300: loss = 1.519459, step_size = 0.161742, min_loss_found = 1.519237\n",
      "Iteration 9400: loss = 1.519455, step_size = 0.186471, min_loss_found = 1.519237\n",
      "Iteration 9500: loss = 1.519360, step_size = 0.158539, min_loss_found = 1.519237\n",
      "Iteration 9600: loss = 1.519446, step_size = 0.150437, min_loss_found = 1.519237\n",
      "Iteration 9700: loss = 1.519506, step_size = 0.242701, min_loss_found = 1.519237\n",
      "Iteration 9800: loss = 1.519471, step_size = 0.220131, min_loss_found = 1.519237\n",
      "Iteration 9900: loss = 1.519510, step_size = 0.244054, min_loss_found = 1.519237\n",
      "Iteration 10000: loss = 1.519572, step_size = 0.178309, min_loss_found = 1.519237\n",
      "Iteration 10100: loss = 1.519463, step_size = 0.173783, min_loss_found = 1.519237\n",
      "Iteration 10200: loss = 1.519457, step_size = 0.142998, min_loss_found = 1.519237\n",
      "Iteration 10300: loss = 1.519446, step_size = 0.182887, min_loss_found = 1.519237\n",
      "Iteration 10400: loss = 1.519438, step_size = 0.132953, min_loss_found = 1.519237\n",
      "Iteration 10500: loss = 1.519481, step_size = 0.179298, min_loss_found = 1.519237\n",
      "Iteration 10600: loss = 1.519454, step_size = 0.221201, min_loss_found = 1.519237\n",
      "Iteration 10700: loss = 1.519425, step_size = 0.168183, min_loss_found = 1.519237\n",
      "Iteration 10800: loss = 1.519295, step_size = 0.121069, min_loss_found = 1.519237\n",
      "Iteration 10900: loss = 1.519369, step_size = 0.155253, min_loss_found = 1.519237\n",
      "Iteration 11000: loss = 1.519390, step_size = 0.180705, min_loss_found = 1.519237\n",
      "Iteration 11100: loss = 1.519435, step_size = 0.163495, min_loss_found = 1.519237\n",
      "Iteration 11200: loss = 1.519493, step_size = 0.144428, min_loss_found = 1.519237\n",
      "Iteration 11300: loss = 1.519371, step_size = 0.159115, min_loss_found = 1.519237\n",
      "Iteration 11400: loss = 1.519399, step_size = 0.159740, min_loss_found = 1.519237\n",
      "Iteration 11500: loss = 1.519496, step_size = 0.173834, min_loss_found = 1.519237\n",
      "Iteration 11600: loss = 1.519345, step_size = 0.157686, min_loss_found = 1.519237\n",
      "Iteration 11700: loss = 1.519429, step_size = 0.167279, min_loss_found = 1.519237\n",
      "Iteration 11800: loss = 1.519422, step_size = 0.169775, min_loss_found = 1.519237\n",
      "Iteration 11900: loss = 1.519541, step_size = 0.143979, min_loss_found = 1.519237\n",
      "Iteration 12000: loss = 1.519384, step_size = 0.202979, min_loss_found = 1.519237\n",
      "Iteration 12100: loss = 1.519381, step_size = 0.163566, min_loss_found = 1.519237\n",
      "Iteration 12200: loss = 1.519351, step_size = 0.152905, min_loss_found = 1.519237\n",
      "Iteration 12300: loss = 1.519360, step_size = 0.139643, min_loss_found = 1.519237\n",
      "Iteration 12400: loss = 1.519390, step_size = 0.138251, min_loss_found = 1.519237\n",
      "Iteration 12500: loss = 1.519476, step_size = 0.189625, min_loss_found = 1.519237\n",
      "Iteration 12600: loss = 1.519363, step_size = 0.200073, min_loss_found = 1.519237\n",
      "Iteration 12700: loss = 1.519450, step_size = 0.194946, min_loss_found = 1.519237\n",
      "Iteration 12800: loss = 1.519436, step_size = 0.169470, min_loss_found = 1.519237\n",
      "Iteration 12900: loss = 1.519445, step_size = 0.168409, min_loss_found = 1.519237\n",
      "Iteration 13000: loss = 1.519452, step_size = 0.226813, min_loss_found = 1.519237\n",
      "Iteration 13100: loss = 1.519300, step_size = 0.122803, min_loss_found = 1.519237\n",
      "Iteration 13200: loss = 1.519432, step_size = 0.169164, min_loss_found = 1.519237\n",
      "Iteration 13300: loss = 1.519426, step_size = 0.169675, min_loss_found = 1.519237\n",
      "Iteration 13400: loss = 1.519387, step_size = 0.208388, min_loss_found = 1.519237\n",
      "Iteration 13500: loss = 1.519449, step_size = 0.233640, min_loss_found = 1.519237\n",
      "Iteration 13600: loss = 1.519457, step_size = 0.173167, min_loss_found = 1.519237\n",
      "Iteration 13700: loss = 1.519513, step_size = 0.177913, min_loss_found = 1.519237\n",
      "Iteration 13800: loss = 1.519369, step_size = 0.162078, min_loss_found = 1.519237\n",
      "Iteration 13900: loss = 1.519345, step_size = 0.158089, min_loss_found = 1.519237\n",
      "Iteration 14000: loss = 1.519417, step_size = 0.139348, min_loss_found = 1.519232\n",
      "Iteration 14100: loss = 1.519493, step_size = 0.147976, min_loss_found = 1.519232\n",
      "Iteration 14200: loss = 1.519401, step_size = 0.139448, min_loss_found = 1.519232\n",
      "Iteration 14300: loss = 1.519335, step_size = 0.157043, min_loss_found = 1.519232\n",
      "Iteration 14400: loss = 1.519449, step_size = 0.180010, min_loss_found = 1.519232\n",
      "Iteration 14500: loss = 1.519354, step_size = 0.242067, min_loss_found = 1.519232\n",
      "Iteration 14600: loss = 1.519460, step_size = 0.166315, min_loss_found = 1.519232\n",
      "Iteration 14700: loss = 1.519340, step_size = 0.132837, min_loss_found = 1.519232\n",
      "Iteration 14800: loss = 1.519501, step_size = 0.171936, min_loss_found = 1.519221\n",
      "Iteration 14900: loss = 1.519389, step_size = 0.162850, min_loss_found = 1.519221\n",
      "Iteration 15000: loss = 1.519518, step_size = 0.148563, min_loss_found = 1.519221\n",
      "Iteration 15100: loss = 1.519258, step_size = 0.151099, min_loss_found = 1.519221\n",
      "Iteration 15200: loss = 1.519399, step_size = 0.142396, min_loss_found = 1.519221\n",
      "Iteration 15300: loss = 1.519342, step_size = 0.163593, min_loss_found = 1.519221\n",
      "Iteration 15400: loss = 1.519386, step_size = 0.169155, min_loss_found = 1.519221\n",
      "Iteration 15500: loss = 1.519315, step_size = 0.164922, min_loss_found = 1.519221\n",
      "Iteration 15600: loss = 1.519334, step_size = 0.124443, min_loss_found = 1.519221\n",
      "Iteration 15700: loss = 1.519351, step_size = 0.154335, min_loss_found = 1.519221\n",
      "Iteration 15800: loss = 1.519316, step_size = 0.156199, min_loss_found = 1.519221\n",
      "Iteration 15900: loss = 1.519334, step_size = 0.155853, min_loss_found = 1.519221\n",
      "Iteration 16000: loss = 1.519296, step_size = 0.121791, min_loss_found = 1.519221\n",
      "Iteration 16100: loss = 1.519361, step_size = 0.159994, min_loss_found = 1.519221\n",
      "Iteration 16200: loss = 1.519374, step_size = 0.139336, min_loss_found = 1.519221\n",
      "Iteration 16300: loss = 1.519403, step_size = 0.134386, min_loss_found = 1.519221\n",
      "Iteration 16400: loss = 1.519471, step_size = 0.171698, min_loss_found = 1.519221\n",
      "Iteration 16500: loss = 1.519304, step_size = 0.236756, min_loss_found = 1.519221\n",
      "Iteration 16600: loss = 1.519481, step_size = 0.216259, min_loss_found = 1.519221\n",
      "Iteration 16700: loss = 1.519327, step_size = 0.158686, min_loss_found = 1.519221\n",
      "Iteration 16800: loss = 1.519422, step_size = 0.198480, min_loss_found = 1.519221\n",
      "Iteration 16900: loss = 1.519432, step_size = 0.131292, min_loss_found = 1.519221\n",
      "Iteration 17000: loss = 1.519382, step_size = 0.171411, min_loss_found = 1.519221\n",
      "Iteration 17100: loss = 1.519409, step_size = 0.147284, min_loss_found = 1.519221\n",
      "Iteration 17200: loss = 1.519505, step_size = 0.173587, min_loss_found = 1.519221\n",
      "Iteration 17300: loss = 1.519545, step_size = 0.152233, min_loss_found = 1.519221\n",
      "Iteration 17400: loss = 1.519450, step_size = 0.142878, min_loss_found = 1.519221\n",
      "Iteration 17500: loss = 1.519359, step_size = 0.141137, min_loss_found = 1.519221\n",
      "Iteration 17600: loss = 1.519443, step_size = 0.168770, min_loss_found = 1.519208\n",
      "Iteration 17700: loss = 1.519345, step_size = 0.216222, min_loss_found = 1.519208\n",
      "Iteration 17800: loss = 1.519424, step_size = 0.138839, min_loss_found = 1.519208\n",
      "Iteration 17900: loss = 1.519452, step_size = 0.171147, min_loss_found = 1.519208\n",
      "Iteration 18000: loss = 1.519392, step_size = 0.217815, min_loss_found = 1.519208\n",
      "Iteration 18100: loss = 1.519420, step_size = 0.135416, min_loss_found = 1.519208\n",
      "Iteration 18200: loss = 1.519227, step_size = 0.133210, min_loss_found = 1.519208\n",
      "Iteration 18300: loss = 1.519348, step_size = 0.142576, min_loss_found = 1.519208\n",
      "Iteration 18400: loss = 1.519292, step_size = 0.147094, min_loss_found = 1.519208\n",
      "Iteration 18500: loss = 1.519467, step_size = 0.174215, min_loss_found = 1.519208\n",
      "Iteration 18600: loss = 1.519401, step_size = 0.132605, min_loss_found = 1.519208\n",
      "Iteration 18700: loss = 1.519526, step_size = 0.149934, min_loss_found = 1.519208\n",
      "Iteration 18800: loss = 1.519346, step_size = 0.156878, min_loss_found = 1.519208\n",
      "Iteration 18900: loss = 1.519298, step_size = 0.184478, min_loss_found = 1.519208\n",
      "Iteration 19000: loss = 1.519364, step_size = 0.173737, min_loss_found = 1.519208\n",
      "Iteration 19100: loss = 1.519336, step_size = 0.166095, min_loss_found = 1.519208\n",
      "Iteration 19200: loss = 1.519350, step_size = 0.216262, min_loss_found = 1.519208\n",
      "Iteration 19300: loss = 1.519483, step_size = 0.229193, min_loss_found = 1.519208\n",
      "Iteration 19400: loss = 1.519422, step_size = 0.162251, min_loss_found = 1.519208\n",
      "Iteration 19500: loss = 1.519430, step_size = 0.160343, min_loss_found = 1.519208\n",
      "Iteration 19600: loss = 1.519302, step_size = 0.124910, min_loss_found = 1.519208\n",
      "Iteration 19700: loss = 1.519418, step_size = 0.134562, min_loss_found = 1.519208\n",
      "Iteration 19800: loss = 1.519359, step_size = 0.162206, min_loss_found = 1.519208\n",
      "Iteration 19900: loss = 1.519454, step_size = 0.168100, min_loss_found = 1.519208\n",
      "Iteration 20000: loss = 1.519340, step_size = 0.173405, min_loss_found = 1.519208\n",
      "Iteration 20100: loss = 1.519446, step_size = 0.168475, min_loss_found = 1.519208\n",
      "Iteration 20200: loss = 1.519288, step_size = 0.125820, min_loss_found = 1.519208\n",
      "Iteration 20300: loss = 1.519400, step_size = 0.179825, min_loss_found = 1.519208\n",
      "Iteration 20400: loss = 1.519392, step_size = 0.162452, min_loss_found = 1.519208\n",
      "Iteration 20500: loss = 1.519462, step_size = 0.133021, min_loss_found = 1.519208\n",
      "Iteration 20600: loss = 1.519351, step_size = 0.156754, min_loss_found = 1.519208\n",
      "Iteration 20700: loss = 1.519339, step_size = 0.157316, min_loss_found = 1.519208\n",
      "Iteration 20800: loss = 1.519295, step_size = 0.124704, min_loss_found = 1.519208\n",
      "Iteration 20900: loss = 1.519350, step_size = 0.160190, min_loss_found = 1.519208\n",
      "Iteration 21000: loss = 1.519350, step_size = 0.152392, min_loss_found = 1.519208\n",
      "Iteration 21100: loss = 1.519337, step_size = 0.221311, min_loss_found = 1.519208\n",
      "Iteration 21200: loss = 1.519484, step_size = 0.143598, min_loss_found = 1.519208\n",
      "Iteration 21300: loss = 1.519386, step_size = 0.137858, min_loss_found = 1.519208\n",
      "Iteration 21400: loss = 1.519418, step_size = 0.147414, min_loss_found = 1.519208\n",
      "Iteration 21500: loss = 1.519371, step_size = 0.222319, min_loss_found = 1.519208\n",
      "Iteration 21600: loss = 1.519453, step_size = 0.155864, min_loss_found = 1.519208\n",
      "Iteration 21700: loss = 1.519393, step_size = 0.151862, min_loss_found = 1.519208\n",
      "Iteration 21800: loss = 1.519475, step_size = 0.262132, min_loss_found = 1.519208\n",
      "Iteration 21900: loss = 1.519387, step_size = 0.165300, min_loss_found = 1.519208\n",
      "Iteration 22000: loss = 1.519322, step_size = 0.171856, min_loss_found = 1.519208\n",
      "Iteration 22100: loss = 1.519446, step_size = 0.231336, min_loss_found = 1.519208\n",
      "Iteration 22200: loss = 1.519267, step_size = 0.118182, min_loss_found = 1.519208\n",
      "Iteration 22300: loss = 1.519317, step_size = 0.137131, min_loss_found = 1.519208\n",
      "Iteration 22400: loss = 1.519266, step_size = 0.151823, min_loss_found = 1.519208\n",
      "Iteration 22500: loss = 1.519365, step_size = 0.135088, min_loss_found = 1.519208\n",
      "Iteration 22600: loss = 1.519448, step_size = 0.227190, min_loss_found = 1.519208\n",
      "Iteration 22700: loss = 1.519336, step_size = 0.157069, min_loss_found = 1.519208\n",
      "Iteration 22800: loss = 1.519479, step_size = 0.182020, min_loss_found = 1.519208\n",
      "Iteration 22900: loss = 1.519440, step_size = 0.142768, min_loss_found = 1.519208\n",
      "Iteration 23000: loss = 1.519245, step_size = 0.232421, min_loss_found = 1.519208\n",
      "Iteration 23100: loss = 1.519329, step_size = 0.129034, min_loss_found = 1.519208\n",
      "Iteration 23200: loss = 1.519424, step_size = 0.170510, min_loss_found = 1.519208\n",
      "Iteration 23300: loss = 1.519326, step_size = 0.130913, min_loss_found = 1.519208\n",
      "Iteration 23400: loss = 1.519428, step_size = 0.147864, min_loss_found = 1.519208\n",
      "Iteration 23500: loss = 1.519251, step_size = 0.159374, min_loss_found = 1.519208\n",
      "Iteration 23600: loss = 1.519368, step_size = 0.200697, min_loss_found = 1.519208\n",
      "Iteration 23700: loss = 1.519340, step_size = 0.213983, min_loss_found = 1.519208\n",
      "Iteration 23800: loss = 1.519353, step_size = 0.220745, min_loss_found = 1.519208\n",
      "Iteration 23900: loss = 1.519326, step_size = 0.127184, min_loss_found = 1.519208\n",
      "Iteration 24000: loss = 1.519269, step_size = 0.152254, min_loss_found = 1.519208\n",
      "Iteration 24100: loss = 1.519390, step_size = 0.174966, min_loss_found = 1.519208\n",
      "Iteration 24200: loss = 1.519387, step_size = 0.220051, min_loss_found = 1.519208\n",
      "Iteration 24300: loss = 1.519425, step_size = 0.156898, min_loss_found = 1.519208\n",
      "Iteration 24400: loss = 1.519336, step_size = 0.138807, min_loss_found = 1.519208\n",
      "Iteration 24500: loss = 1.519400, step_size = 0.221712, min_loss_found = 1.519208\n",
      "Iteration 24600: loss = 1.519318, step_size = 0.227228, min_loss_found = 1.519208\n",
      "Iteration 24700: loss = 1.519457, step_size = 0.144305, min_loss_found = 1.519208\n",
      "Iteration 24800: loss = 1.519367, step_size = 0.131129, min_loss_found = 1.519208\n",
      "Iteration 24900: loss = 1.519376, step_size = 0.143503, min_loss_found = 1.519208\n",
      "Iteration 25000: loss = 1.519356, step_size = 0.134162, min_loss_found = 1.519208\n",
      "Iteration 25100: loss = 1.519414, step_size = 0.224980, min_loss_found = 1.519208\n",
      "Iteration 25200: loss = 1.519368, step_size = 0.244316, min_loss_found = 1.519208\n",
      "Iteration 25300: loss = 1.519412, step_size = 0.169383, min_loss_found = 1.519208\n",
      "Iteration 25400: loss = 1.519460, step_size = 0.152242, min_loss_found = 1.519208\n",
      "Iteration 25500: loss = 1.519511, step_size = 0.218914, min_loss_found = 1.519208\n",
      "Iteration 25600: loss = 1.519296, step_size = 0.202500, min_loss_found = 1.519208\n",
      "Iteration 25700: loss = 1.519322, step_size = 0.227764, min_loss_found = 1.519208\n",
      "Iteration 25800: loss = 1.519324, step_size = 0.171445, min_loss_found = 1.519208\n",
      "Iteration 25900: loss = 1.519320, step_size = 0.211998, min_loss_found = 1.519208\n",
      "Iteration 26000: loss = 1.519410, step_size = 0.230059, min_loss_found = 1.519208\n",
      "Iteration 26100: loss = 1.519363, step_size = 0.165823, min_loss_found = 1.519208\n",
      "Iteration 26200: loss = 1.519447, step_size = 0.171975, min_loss_found = 1.519208\n",
      "Iteration 26300: loss = 1.519422, step_size = 0.179229, min_loss_found = 1.519208\n",
      "Iteration 26400: loss = 1.519415, step_size = 0.148306, min_loss_found = 1.519208\n",
      "Iteration 26500: loss = 1.519372, step_size = 0.143644, min_loss_found = 1.519208\n",
      "Iteration 26600: loss = 1.519343, step_size = 0.210693, min_loss_found = 1.519208\n",
      "Iteration 26700: loss = 1.519265, step_size = 0.146731, min_loss_found = 1.519208\n",
      "Iteration 26800: loss = 1.519253, step_size = 0.132009, min_loss_found = 1.519208\n",
      "Iteration 26900: loss = 1.519431, step_size = 0.171043, min_loss_found = 1.519208\n",
      "Iteration 27000: loss = 1.519422, step_size = 0.135722, min_loss_found = 1.519208\n",
      "Iteration 27100: loss = 1.519334, step_size = 0.153562, min_loss_found = 1.519208\n",
      "Iteration 27200: loss = 1.519358, step_size = 0.142799, min_loss_found = 1.519208\n",
      "Iteration 27300: loss = 1.519311, step_size = 0.136901, min_loss_found = 1.519208\n",
      "Iteration 27400: loss = 1.519337, step_size = 0.160355, min_loss_found = 1.519208\n",
      "Iteration 27500: loss = 1.519310, step_size = 0.122360, min_loss_found = 1.519208\n",
      "Iteration 27600: loss = 1.519296, step_size = 0.158288, min_loss_found = 1.519208\n",
      "Iteration 27700: loss = 1.519394, step_size = 0.142603, min_loss_found = 1.519208\n",
      "Iteration 27800: loss = 1.519346, step_size = 0.213965, min_loss_found = 1.519208\n",
      "Iteration 27900: loss = 1.519469, step_size = 0.154979, min_loss_found = 1.519208\n",
      "Iteration 28000: loss = 1.519337, step_size = 0.208394, min_loss_found = 1.519208\n",
      "Iteration 28100: loss = 1.519264, step_size = 0.178228, min_loss_found = 1.519208\n",
      "Iteration 28200: loss = 1.519334, step_size = 0.159441, min_loss_found = 1.519208\n",
      "Iteration 28300: loss = 1.519275, step_size = 0.122502, min_loss_found = 1.519208\n",
      "Iteration 28400: loss = 1.519301, step_size = 0.156757, min_loss_found = 1.519208\n",
      "Iteration 28500: loss = 1.519312, step_size = 0.154581, min_loss_found = 1.519208\n",
      "Iteration 28600: loss = 1.519395, step_size = 0.137753, min_loss_found = 1.519208\n",
      "Iteration 28700: loss = 1.519288, step_size = 0.153026, min_loss_found = 1.519208\n",
      "Iteration 28800: loss = 1.519276, step_size = 0.218384, min_loss_found = 1.519208\n",
      "Iteration 28900: loss = 1.519391, step_size = 0.176163, min_loss_found = 1.519208\n",
      "Iteration 29000: loss = 1.519434, step_size = 0.157827, min_loss_found = 1.519208\n",
      "Iteration 29100: loss = 1.519387, step_size = 0.235911, min_loss_found = 1.519208\n",
      "Iteration 29200: loss = 1.519410, step_size = 0.167995, min_loss_found = 1.519208\n",
      "Iteration 29300: loss = 1.519353, step_size = 0.144069, min_loss_found = 1.519208\n",
      "Iteration 29400: loss = 1.519347, step_size = 0.126187, min_loss_found = 1.519208\n",
      "Iteration 29500: loss = 1.519273, step_size = 0.141611, min_loss_found = 1.519208\n",
      "Iteration 29600: loss = 1.519456, step_size = 0.187265, min_loss_found = 1.519208\n",
      "Iteration 29700: loss = 1.519329, step_size = 0.173319, min_loss_found = 1.519204\n",
      "Iteration 29800: loss = 1.519393, step_size = 0.138651, min_loss_found = 1.519204\n",
      "Iteration 29900: loss = 1.519370, step_size = 0.129861, min_loss_found = 1.519204\n",
      "Iteration 30000: loss = 1.519451, step_size = 0.142911, min_loss_found = 1.519204\n",
      "Iteration 30100: loss = 1.519290, step_size = 0.153443, min_loss_found = 1.519204\n",
      "Iteration 30200: loss = 1.519295, step_size = 0.152443, min_loss_found = 1.519204\n",
      "Iteration 30300: loss = 1.519414, step_size = 0.133556, min_loss_found = 1.519192\n",
      "Iteration 30400: loss = 1.519246, step_size = 0.143890, min_loss_found = 1.519192\n",
      "Iteration 30500: loss = 1.519344, step_size = 0.135770, min_loss_found = 1.519192\n",
      "Iteration 30600: loss = 1.519389, step_size = 0.185888, min_loss_found = 1.519192\n",
      "Iteration 30700: loss = 1.519476, step_size = 0.219978, min_loss_found = 1.519192\n",
      "Iteration 30800: loss = 1.519453, step_size = 0.204860, min_loss_found = 1.519192\n",
      "Iteration 30900: loss = 1.519426, step_size = 0.144200, min_loss_found = 1.519192\n",
      "Iteration 31000: loss = 1.519279, step_size = 0.124513, min_loss_found = 1.519192\n",
      "Iteration 31100: loss = 1.519246, step_size = 0.169661, min_loss_found = 1.519192\n",
      "Iteration 31200: loss = 1.519312, step_size = 0.140061, min_loss_found = 1.519192\n",
      "Iteration 31300: loss = 1.519409, step_size = 0.133749, min_loss_found = 1.519192\n",
      "Iteration 31400: loss = 1.519404, step_size = 0.139476, min_loss_found = 1.519192\n",
      "Iteration 31500: loss = 1.519506, step_size = 0.169127, min_loss_found = 1.519192\n",
      "Iteration 31600: loss = 1.519304, step_size = 0.196649, min_loss_found = 1.519192\n",
      "Iteration 31700: loss = 1.519430, step_size = 0.171998, min_loss_found = 1.519192\n",
      "Iteration 31800: loss = 1.519269, step_size = 0.184213, min_loss_found = 1.519192\n",
      "Iteration 31900: loss = 1.519382, step_size = 0.169998, min_loss_found = 1.519192\n",
      "Iteration 32000: loss = 1.519497, step_size = 0.140630, min_loss_found = 1.519192\n",
      "Iteration 32100: loss = 1.519361, step_size = 0.171604, min_loss_found = 1.519192\n",
      "Iteration 32200: loss = 1.519247, step_size = 0.158619, min_loss_found = 1.519192\n",
      "Iteration 32300: loss = 1.519295, step_size = 0.224910, min_loss_found = 1.519192\n",
      "Iteration 32400: loss = 1.519441, step_size = 0.142841, min_loss_found = 1.519192\n",
      "Iteration 32500: loss = 1.519334, step_size = 0.136288, min_loss_found = 1.519192\n",
      "Iteration 32600: loss = 1.519538, step_size = 0.190822, min_loss_found = 1.519192\n",
      "Iteration 32700: loss = 1.519329, step_size = 0.155612, min_loss_found = 1.519192\n",
      "Iteration 32800: loss = 1.519373, step_size = 0.198198, min_loss_found = 1.519192\n",
      "Iteration 32900: loss = 1.519418, step_size = 0.135170, min_loss_found = 1.519192\n",
      "Iteration 33000: loss = 1.519448, step_size = 0.172975, min_loss_found = 1.519192\n",
      "Iteration 33100: loss = 1.519355, step_size = 0.131017, min_loss_found = 1.519192\n",
      "Iteration 33200: loss = 1.519289, step_size = 0.190876, min_loss_found = 1.519192\n",
      "Iteration 33300: loss = 1.519401, step_size = 0.166769, min_loss_found = 1.519192\n",
      "Iteration 33400: loss = 1.519317, step_size = 0.185066, min_loss_found = 1.519192\n",
      "Iteration 33500: loss = 1.519398, step_size = 0.227535, min_loss_found = 1.519192\n",
      "Iteration 33600: loss = 1.519336, step_size = 0.180446, min_loss_found = 1.519192\n",
      "Iteration 33700: loss = 1.519285, step_size = 0.187022, min_loss_found = 1.519192\n",
      "Iteration 33800: loss = 1.519457, step_size = 0.156525, min_loss_found = 1.519192\n",
      "Iteration 33900: loss = 1.519371, step_size = 0.132824, min_loss_found = 1.519192\n",
      "Iteration 34000: loss = 1.519298, step_size = 0.148820, min_loss_found = 1.519192\n",
      "Iteration 34100: loss = 1.519382, step_size = 0.136919, min_loss_found = 1.519192\n",
      "Iteration 34200: loss = 1.519390, step_size = 0.134583, min_loss_found = 1.519192\n",
      "Iteration 34300: loss = 1.519255, step_size = 0.137679, min_loss_found = 1.519192\n",
      "Iteration 34400: loss = 1.519296, step_size = 0.204214, min_loss_found = 1.519192\n",
      "Iteration 34500: loss = 1.519383, step_size = 0.168106, min_loss_found = 1.519192\n",
      "Iteration 34600: loss = 1.519361, step_size = 0.158027, min_loss_found = 1.519192\n",
      "Iteration 34700: loss = 1.519366, step_size = 0.130009, min_loss_found = 1.519192\n",
      "Iteration 34800: loss = 1.519411, step_size = 0.152366, min_loss_found = 1.519192\n",
      "Iteration 34900: loss = 1.519283, step_size = 0.142583, min_loss_found = 1.519183\n",
      "Iteration 35000: loss = 1.519392, step_size = 0.166024, min_loss_found = 1.519183\n",
      "Iteration 35100: loss = 1.519314, step_size = 0.177685, min_loss_found = 1.519183\n",
      "Iteration 35200: loss = 1.519419, step_size = 0.168397, min_loss_found = 1.519183\n",
      "Iteration 35300: loss = 1.519294, step_size = 0.146770, min_loss_found = 1.519183\n",
      "Iteration 35400: loss = 1.519385, step_size = 0.170190, min_loss_found = 1.519183\n",
      "Iteration 35500: loss = 1.519371, step_size = 0.144001, min_loss_found = 1.519183\n",
      "Iteration 35600: loss = 1.519372, step_size = 0.157761, min_loss_found = 1.519183\n",
      "Iteration 35700: loss = 1.519405, step_size = 0.219759, min_loss_found = 1.519183\n",
      "Iteration 35800: loss = 1.519443, step_size = 0.167371, min_loss_found = 1.519183\n",
      "Iteration 35900: loss = 1.519338, step_size = 0.175058, min_loss_found = 1.519183\n",
      "Iteration 36000: loss = 1.519410, step_size = 0.166632, min_loss_found = 1.519183\n",
      "Iteration 36100: loss = 1.519388, step_size = 0.161002, min_loss_found = 1.519183\n",
      "Iteration 36200: loss = 1.519337, step_size = 0.155965, min_loss_found = 1.519183\n",
      "Iteration 36300: loss = 1.519477, step_size = 0.140595, min_loss_found = 1.519183\n",
      "Iteration 36400: loss = 1.519441, step_size = 0.185789, min_loss_found = 1.519183\n",
      "Iteration 36500: loss = 1.519404, step_size = 0.124515, min_loss_found = 1.519183\n",
      "Iteration 36600: loss = 1.519328, step_size = 0.156038, min_loss_found = 1.519183\n",
      "Iteration 36700: loss = 1.519493, step_size = 0.154883, min_loss_found = 1.519183\n",
      "Iteration 36800: loss = 1.519398, step_size = 0.201541, min_loss_found = 1.519183\n",
      "Iteration 36900: loss = 1.519369, step_size = 0.163386, min_loss_found = 1.519183\n",
      "Iteration 37000: loss = 1.519397, step_size = 0.182226, min_loss_found = 1.519183\n",
      "Iteration 37100: loss = 1.519427, step_size = 0.185141, min_loss_found = 1.519183\n",
      "Iteration 37200: loss = 1.519377, step_size = 0.132990, min_loss_found = 1.519183\n",
      "Iteration 37300: loss = 1.519250, step_size = 0.135396, min_loss_found = 1.519183\n",
      "Iteration 37400: loss = 1.519326, step_size = 0.167389, min_loss_found = 1.519183\n",
      "Iteration 37500: loss = 1.519428, step_size = 0.165877, min_loss_found = 1.519183\n",
      "Iteration 37600: loss = 1.519331, step_size = 0.127892, min_loss_found = 1.519183\n",
      "Iteration 37700: loss = 1.519293, step_size = 0.202054, min_loss_found = 1.519183\n",
      "Iteration 37800: loss = 1.519453, step_size = 0.171362, min_loss_found = 1.519183\n",
      "Iteration 37900: loss = 1.519344, step_size = 0.217438, min_loss_found = 1.519183\n",
      "Iteration 38000: loss = 1.519321, step_size = 0.137905, min_loss_found = 1.519183\n",
      "Iteration 38100: loss = 1.519291, step_size = 0.154557, min_loss_found = 1.519183\n",
      "Iteration 38200: loss = 1.519371, step_size = 0.136573, min_loss_found = 1.519183\n",
      "Iteration 38300: loss = 1.519300, step_size = 0.208818, min_loss_found = 1.519183\n",
      "Iteration 38400: loss = 1.519337, step_size = 0.248272, min_loss_found = 1.519183\n",
      "Iteration 38500: loss = 1.519255, step_size = 0.160746, min_loss_found = 1.519183\n",
      "Iteration 38600: loss = 1.519306, step_size = 0.153636, min_loss_found = 1.519183\n",
      "Iteration 38700: loss = 1.519422, step_size = 0.170235, min_loss_found = 1.519183\n",
      "Iteration 38800: loss = 1.519377, step_size = 0.153064, min_loss_found = 1.519178\n",
      "Iteration 38900: loss = 1.519384, step_size = 0.160891, min_loss_found = 1.519178\n",
      "Iteration 39000: loss = 1.519275, step_size = 0.150270, min_loss_found = 1.519178\n",
      "Iteration 39100: loss = 1.519432, step_size = 0.180319, min_loss_found = 1.519178\n",
      "Iteration 39200: loss = 1.519235, step_size = 0.141358, min_loss_found = 1.519178\n",
      "Iteration 39300: loss = 1.519342, step_size = 0.165160, min_loss_found = 1.519178\n",
      "Iteration 39400: loss = 1.519334, step_size = 0.126649, min_loss_found = 1.519178\n",
      "Iteration 39500: loss = 1.519316, step_size = 0.165750, min_loss_found = 1.519178\n",
      "Iteration 39600: loss = 1.519447, step_size = 0.149782, min_loss_found = 1.519178\n",
      "Iteration 39700: loss = 1.519336, step_size = 0.158310, min_loss_found = 1.519178\n",
      "Iteration 39800: loss = 1.519299, step_size = 0.141009, min_loss_found = 1.519178\n",
      "Iteration 39900: loss = 1.519312, step_size = 0.199075, min_loss_found = 1.519178\n",
      "Iteration 40000: loss = 1.519393, step_size = 0.163208, min_loss_found = 1.519178\n",
      "Iteration 40100: loss = 1.519374, step_size = 0.133011, min_loss_found = 1.519178\n",
      "Iteration 40200: loss = 1.519341, step_size = 0.133733, min_loss_found = 1.519178\n",
      "Iteration 40300: loss = 1.519327, step_size = 0.192700, min_loss_found = 1.519178\n",
      "Iteration 40400: loss = 1.519306, step_size = 0.155271, min_loss_found = 1.519178\n",
      "Iteration 40500: loss = 1.519364, step_size = 0.162703, min_loss_found = 1.519178\n",
      "Iteration 40600: loss = 1.519439, step_size = 0.221210, min_loss_found = 1.519178\n",
      "Iteration 40700: loss = 1.519457, step_size = 0.205385, min_loss_found = 1.519172\n",
      "Iteration 40800: loss = 1.519400, step_size = 0.166689, min_loss_found = 1.519172\n",
      "Iteration 40900: loss = 1.519317, step_size = 0.213442, min_loss_found = 1.519172\n",
      "Iteration 41000: loss = 1.519417, step_size = 0.135978, min_loss_found = 1.519172\n",
      "Iteration 41100: loss = 1.519308, step_size = 0.130431, min_loss_found = 1.519172\n",
      "Iteration 41200: loss = 1.519375, step_size = 0.152106, min_loss_found = 1.519172\n",
      "Iteration 41300: loss = 1.519339, step_size = 0.158641, min_loss_found = 1.519172\n",
      "Iteration 41400: loss = 1.519303, step_size = 0.207532, min_loss_found = 1.519172\n",
      "Iteration 41500: loss = 1.519278, step_size = 0.203803, min_loss_found = 1.519172\n",
      "Iteration 41600: loss = 1.519368, step_size = 0.153022, min_loss_found = 1.519172\n",
      "Iteration 41700: loss = 1.519380, step_size = 0.146692, min_loss_found = 1.519172\n",
      "Iteration 41800: loss = 1.519265, step_size = 0.146423, min_loss_found = 1.519172\n",
      "Iteration 41900: loss = 1.519402, step_size = 0.151008, min_loss_found = 1.519172\n",
      "Iteration 42000: loss = 1.519455, step_size = 0.142429, min_loss_found = 1.519172\n",
      "Iteration 42100: loss = 1.519270, step_size = 0.208725, min_loss_found = 1.519172\n",
      "Iteration 42200: loss = 1.519362, step_size = 0.218593, min_loss_found = 1.519172\n",
      "Iteration 42300: loss = 1.519264, step_size = 0.120018, min_loss_found = 1.519172\n",
      "Iteration 42400: loss = 1.519355, step_size = 0.151450, min_loss_found = 1.519172\n",
      "Iteration 42500: loss = 1.519341, step_size = 0.127213, min_loss_found = 1.519172\n",
      "Iteration 42600: loss = 1.519272, step_size = 0.141029, min_loss_found = 1.519172\n",
      "Iteration 42700: loss = 1.519256, step_size = 0.121163, min_loss_found = 1.519172\n",
      "Iteration 42800: loss = 1.519278, step_size = 0.206307, min_loss_found = 1.519172\n",
      "Iteration 42900: loss = 1.519291, step_size = 0.151973, min_loss_found = 1.519172\n",
      "Iteration 43000: loss = 1.519268, step_size = 0.118643, min_loss_found = 1.519172\n",
      "Iteration 43100: loss = 1.519474, step_size = 0.185262, min_loss_found = 1.519172\n",
      "Iteration 43200: loss = 1.519388, step_size = 0.165327, min_loss_found = 1.519172\n",
      "Iteration 43300: loss = 1.519246, step_size = 0.111369, min_loss_found = 1.519172\n",
      "Iteration 43400: loss = 1.519371, step_size = 0.162091, min_loss_found = 1.519172\n",
      "Iteration 43500: loss = 1.519247, step_size = 0.137059, min_loss_found = 1.519172\n",
      "Iteration 43600: loss = 1.519245, step_size = 0.135270, min_loss_found = 1.519172\n",
      "Iteration 43700: loss = 1.519370, step_size = 0.209234, min_loss_found = 1.519172\n",
      "Iteration 43800: loss = 1.519329, step_size = 0.215392, min_loss_found = 1.519172\n",
      "Iteration 43900: loss = 1.519416, step_size = 0.165708, min_loss_found = 1.519172\n",
      "Iteration 44000: loss = 1.519324, step_size = 0.123511, min_loss_found = 1.519172\n",
      "Iteration 44100: loss = 1.519345, step_size = 0.196838, min_loss_found = 1.519172\n",
      "Iteration 44200: loss = 1.519305, step_size = 0.210131, min_loss_found = 1.519172\n",
      "Iteration 44300: loss = 1.519434, step_size = 0.170455, min_loss_found = 1.519172\n",
      "Iteration 44400: loss = 1.519247, step_size = 0.128755, min_loss_found = 1.519172\n",
      "Iteration 44500: loss = 1.519400, step_size = 0.135357, min_loss_found = 1.519172\n",
      "Iteration 44600: loss = 1.519343, step_size = 0.132886, min_loss_found = 1.519172\n",
      "Iteration 44700: loss = 1.519301, step_size = 0.132945, min_loss_found = 1.519172\n",
      "Iteration 44800: loss = 1.519282, step_size = 0.123143, min_loss_found = 1.519172\n",
      "Iteration 44900: loss = 1.519317, step_size = 0.144286, min_loss_found = 1.519172\n",
      "Iteration 45000: loss = 1.519312, step_size = 0.206164, min_loss_found = 1.519172\n",
      "Iteration 45100: loss = 1.519318, step_size = 0.163325, min_loss_found = 1.519172\n",
      "Iteration 45200: loss = 1.519253, step_size = 0.128616, min_loss_found = 1.519172\n",
      "Iteration 45300: loss = 1.519324, step_size = 0.155647, min_loss_found = 1.519172\n",
      "Iteration 45400: loss = 1.519318, step_size = 0.156314, min_loss_found = 1.519172\n",
      "Iteration 45500: loss = 1.519416, step_size = 0.143843, min_loss_found = 1.519172\n",
      "Iteration 45600: loss = 1.519358, step_size = 0.175716, min_loss_found = 1.519172\n",
      "Iteration 45700: loss = 1.519370, step_size = 0.158694, min_loss_found = 1.519172\n",
      "Iteration 45800: loss = 1.519367, step_size = 0.168238, min_loss_found = 1.519172\n",
      "Iteration 45900: loss = 1.519404, step_size = 0.167139, min_loss_found = 1.519172\n",
      "Iteration 46000: loss = 1.519345, step_size = 0.215643, min_loss_found = 1.519172\n",
      "Iteration 46100: loss = 1.519314, step_size = 0.155775, min_loss_found = 1.519172\n",
      "Iteration 46200: loss = 1.519223, step_size = 0.145884, min_loss_found = 1.519172\n",
      "Iteration 46300: loss = 1.519261, step_size = 0.203481, min_loss_found = 1.519172\n",
      "Iteration 46400: loss = 1.519217, step_size = 0.157738, min_loss_found = 1.519172\n",
      "Iteration 46500: loss = 1.519273, step_size = 0.173068, min_loss_found = 1.519172\n",
      "Iteration 46600: loss = 1.519341, step_size = 0.133244, min_loss_found = 1.519172\n",
      "Iteration 46700: loss = 1.519386, step_size = 0.214172, min_loss_found = 1.519172\n",
      "Iteration 46800: loss = 1.519383, step_size = 0.214128, min_loss_found = 1.519172\n",
      "Iteration 46900: loss = 1.519315, step_size = 0.197485, min_loss_found = 1.519172\n",
      "Iteration 47000: loss = 1.519359, step_size = 0.156509, min_loss_found = 1.519172\n",
      "Iteration 47100: loss = 1.519423, step_size = 0.165711, min_loss_found = 1.519172\n",
      "Iteration 47200: loss = 1.519226, step_size = 0.181022, min_loss_found = 1.519172\n",
      "Iteration 47300: loss = 1.519246, step_size = 0.205052, min_loss_found = 1.519172\n",
      "Iteration 47400: loss = 1.519294, step_size = 0.151407, min_loss_found = 1.519172\n",
      "Iteration 47500: loss = 1.519529, step_size = 0.150867, min_loss_found = 1.519172\n",
      "Iteration 47600: loss = 1.519326, step_size = 0.161778, min_loss_found = 1.519172\n",
      "Iteration 47700: loss = 1.519330, step_size = 0.156796, min_loss_found = 1.519172\n",
      "Iteration 47800: loss = 1.519416, step_size = 0.133405, min_loss_found = 1.519172\n",
      "Iteration 47900: loss = 1.519451, step_size = 0.218542, min_loss_found = 1.519162\n",
      "Iteration 48000: loss = 1.519324, step_size = 0.158234, min_loss_found = 1.519162\n",
      "Iteration 48100: loss = 1.519292, step_size = 0.152047, min_loss_found = 1.519162\n",
      "Iteration 48200: loss = 1.519376, step_size = 0.164009, min_loss_found = 1.519162\n",
      "Iteration 48300: loss = 1.519277, step_size = 0.153063, min_loss_found = 1.519162\n",
      "Iteration 48400: loss = 1.519504, step_size = 0.180218, min_loss_found = 1.519162\n",
      "Iteration 48500: loss = 1.519279, step_size = 0.155663, min_loss_found = 1.519162\n",
      "Iteration 48600: loss = 1.519242, step_size = 0.149496, min_loss_found = 1.519162\n",
      "Iteration 48700: loss = 1.519308, step_size = 0.156447, min_loss_found = 1.519162\n",
      "Iteration 48800: loss = 1.519357, step_size = 0.176025, min_loss_found = 1.519162\n",
      "Iteration 48900: loss = 1.519347, step_size = 0.214219, min_loss_found = 1.519162\n",
      "Iteration 49000: loss = 1.519362, step_size = 0.120986, min_loss_found = 1.519162\n",
      "Iteration 49100: loss = 1.519311, step_size = 0.154297, min_loss_found = 1.519162\n",
      "Iteration 49200: loss = 1.519272, step_size = 0.148049, min_loss_found = 1.519162\n",
      "Iteration 49300: loss = 1.519268, step_size = 0.156816, min_loss_found = 1.519162\n",
      "Iteration 49400: loss = 1.519309, step_size = 0.155556, min_loss_found = 1.519162\n",
      "Iteration 49500: loss = 1.519415, step_size = 0.156881, min_loss_found = 1.519162\n",
      "Iteration 49600: loss = 1.519311, step_size = 0.136353, min_loss_found = 1.519162\n",
      "Iteration 49700: loss = 1.519305, step_size = 0.176399, min_loss_found = 1.519162\n",
      "Iteration 49800: loss = 1.519440, step_size = 0.137499, min_loss_found = 1.519162\n",
      "Iteration 49900: loss = 1.519322, step_size = 0.212203, min_loss_found = 1.519162\n",
      "Iteration 50000: loss = 1.519301, step_size = 0.155605, min_loss_found = 1.519162\n",
      "Iteration 50100: loss = 1.519363, step_size = 0.135763, min_loss_found = 1.519162\n",
      "Iteration 50200: loss = 1.519283, step_size = 0.154148, min_loss_found = 1.519162\n",
      "Iteration 50300: loss = 1.519349, step_size = 0.212376, min_loss_found = 1.519162\n",
      "Iteration 50400: loss = 1.519321, step_size = 0.156494, min_loss_found = 1.519162\n",
      "Iteration 50500: loss = 1.519258, step_size = 0.125306, min_loss_found = 1.519162\n",
      "Iteration 50600: loss = 1.519404, step_size = 0.219211, min_loss_found = 1.519162\n",
      "Iteration 50700: loss = 1.519358, step_size = 0.139228, min_loss_found = 1.519162\n",
      "Iteration 50800: loss = 1.519335, step_size = 0.137087, min_loss_found = 1.519162\n",
      "Iteration 50900: loss = 1.519390, step_size = 0.137804, min_loss_found = 1.519162\n",
      "Iteration 51000: loss = 1.519314, step_size = 0.155832, min_loss_found = 1.519162\n",
      "Iteration 51100: loss = 1.519268, step_size = 0.148399, min_loss_found = 1.519162\n",
      "Iteration 51200: loss = 1.519302, step_size = 0.124919, min_loss_found = 1.519162\n",
      "Iteration 51300: loss = 1.519279, step_size = 0.206318, min_loss_found = 1.519162\n",
      "Iteration 51400: loss = 1.519423, step_size = 0.167101, min_loss_found = 1.519162\n",
      "Iteration 51500: loss = 1.519287, step_size = 0.211314, min_loss_found = 1.519162\n",
      "Iteration 51600: loss = 1.519264, step_size = 0.163172, min_loss_found = 1.519162\n",
      "Iteration 51700: loss = 1.519395, step_size = 0.218124, min_loss_found = 1.519162\n",
      "Iteration 51800: loss = 1.519276, step_size = 0.139800, min_loss_found = 1.519162\n",
      "Iteration 51900: loss = 1.519294, step_size = 0.214612, min_loss_found = 1.519162\n",
      "Iteration 52000: loss = 1.519306, step_size = 0.120345, min_loss_found = 1.519162\n",
      "Iteration 52100: loss = 1.519294, step_size = 0.167524, min_loss_found = 1.519162\n",
      "Iteration 52200: loss = 1.519301, step_size = 0.207112, min_loss_found = 1.519162\n",
      "Iteration 52300: loss = 1.519282, step_size = 0.149915, min_loss_found = 1.519162\n",
      "Iteration 52400: loss = 1.519351, step_size = 0.215052, min_loss_found = 1.519162\n",
      "Iteration 52500: loss = 1.519230, step_size = 0.116981, min_loss_found = 1.519162\n",
      "Iteration 52600: loss = 1.519204, step_size = 0.152615, min_loss_found = 1.519162\n",
      "Iteration 52700: loss = 1.519299, step_size = 0.138676, min_loss_found = 1.519162\n",
      "Iteration 52800: loss = 1.519343, step_size = 0.207355, min_loss_found = 1.519162\n",
      "Iteration 52900: loss = 1.519170, step_size = 0.159418, min_loss_found = 1.519162\n",
      "Iteration 53000: loss = 1.519430, step_size = 0.168580, min_loss_found = 1.519162\n",
      "Iteration 53100: loss = 1.519389, step_size = 0.126729, min_loss_found = 1.519162\n",
      "Iteration 53200: loss = 1.519304, step_size = 0.221398, min_loss_found = 1.519162\n",
      "Iteration 53300: loss = 1.519261, step_size = 0.121233, min_loss_found = 1.519162\n",
      "Iteration 53400: loss = 1.519353, step_size = 0.129467, min_loss_found = 1.519162\n",
      "Iteration 53500: loss = 1.519352, step_size = 0.130990, min_loss_found = 1.519156\n",
      "Iteration 53600: loss = 1.519321, step_size = 0.131137, min_loss_found = 1.519156\n",
      "Iteration 53700: loss = 1.519343, step_size = 0.215191, min_loss_found = 1.519156\n",
      "Iteration 53800: loss = 1.519354, step_size = 0.147627, min_loss_found = 1.519156\n",
      "Iteration 53900: loss = 1.519292, step_size = 0.163345, min_loss_found = 1.519155\n",
      "Iteration 54000: loss = 1.519347, step_size = 0.132012, min_loss_found = 1.519155\n",
      "Iteration 54100: loss = 1.519434, step_size = 0.173757, min_loss_found = 1.519155\n",
      "Iteration 54200: loss = 1.519453, step_size = 0.142436, min_loss_found = 1.519155\n",
      "Iteration 54300: loss = 1.519379, step_size = 0.194931, min_loss_found = 1.519155\n",
      "Iteration 54400: loss = 1.519381, step_size = 0.161884, min_loss_found = 1.519155\n",
      "Iteration 54500: loss = 1.519368, step_size = 0.163535, min_loss_found = 1.519155\n",
      "Iteration 54600: loss = 1.519456, step_size = 0.142493, min_loss_found = 1.519155\n",
      "Iteration 54700: loss = 1.519284, step_size = 0.153819, min_loss_found = 1.519155\n",
      "Iteration 54800: loss = 1.519279, step_size = 0.133314, min_loss_found = 1.519155\n",
      "Iteration 54900: loss = 1.519260, step_size = 0.129940, min_loss_found = 1.519155\n",
      "Iteration 55000: loss = 1.519325, step_size = 0.152107, min_loss_found = 1.519155\n",
      "Iteration 55100: loss = 1.519407, step_size = 0.131342, min_loss_found = 1.519155\n",
      "Iteration 55200: loss = 1.519359, step_size = 0.133110, min_loss_found = 1.519155\n",
      "Iteration 55300: loss = 1.519282, step_size = 0.118298, min_loss_found = 1.519155\n",
      "Iteration 55400: loss = 1.519348, step_size = 0.141634, min_loss_found = 1.519155\n",
      "Iteration 55500: loss = 1.519290, step_size = 0.214009, min_loss_found = 1.519155\n",
      "Iteration 55600: loss = 1.519353, step_size = 0.152509, min_loss_found = 1.519155\n",
      "Iteration 55700: loss = 1.519309, step_size = 0.234328, min_loss_found = 1.519155\n",
      "Iteration 55800: loss = 1.519362, step_size = 0.167535, min_loss_found = 1.519155\n",
      "Iteration 55900: loss = 1.519294, step_size = 0.157683, min_loss_found = 1.519155\n",
      "Iteration 56000: loss = 1.519349, step_size = 0.140138, min_loss_found = 1.519155\n",
      "Iteration 56100: loss = 1.519338, step_size = 0.158378, min_loss_found = 1.519155\n",
      "Iteration 56200: loss = 1.519272, step_size = 0.188308, min_loss_found = 1.519155\n",
      "Iteration 56300: loss = 1.519279, step_size = 0.145888, min_loss_found = 1.519155\n",
      "Iteration 56400: loss = 1.519412, step_size = 0.167964, min_loss_found = 1.519155\n",
      "Iteration 56500: loss = 1.519370, step_size = 0.121581, min_loss_found = 1.519155\n",
      "Iteration 56600: loss = 1.519233, step_size = 0.126618, min_loss_found = 1.519155\n",
      "Iteration 56700: loss = 1.519347, step_size = 0.128859, min_loss_found = 1.519155\n",
      "Iteration 56800: loss = 1.519244, step_size = 0.122558, min_loss_found = 1.519155\n",
      "Iteration 56900: loss = 1.519358, step_size = 0.155636, min_loss_found = 1.519155\n",
      "Iteration 57000: loss = 1.519317, step_size = 0.125567, min_loss_found = 1.519155\n",
      "Iteration 57100: loss = 1.519332, step_size = 0.154913, min_loss_found = 1.519155\n",
      "Iteration 57200: loss = 1.519258, step_size = 0.147184, min_loss_found = 1.519155\n",
      "Iteration 57300: loss = 1.519285, step_size = 0.164247, min_loss_found = 1.519155\n",
      "Iteration 57400: loss = 1.519365, step_size = 0.135952, min_loss_found = 1.519155\n",
      "Iteration 57500: loss = 1.519365, step_size = 0.161566, min_loss_found = 1.519155\n",
      "Iteration 57600: loss = 1.519182, step_size = 0.154489, min_loss_found = 1.519155\n",
      "Iteration 57700: loss = 1.519377, step_size = 0.198404, min_loss_found = 1.519155\n",
      "Iteration 57800: loss = 1.519308, step_size = 0.148953, min_loss_found = 1.519141\n",
      "Iteration 57900: loss = 1.519296, step_size = 0.115439, min_loss_found = 1.519141\n",
      "Iteration 58000: loss = 1.519376, step_size = 0.135858, min_loss_found = 1.519141\n",
      "Iteration 58100: loss = 1.519303, step_size = 0.182191, min_loss_found = 1.519141\n",
      "Iteration 58200: loss = 1.519256, step_size = 0.155373, min_loss_found = 1.519141\n",
      "Iteration 58300: loss = 1.519349, step_size = 0.158842, min_loss_found = 1.519141\n",
      "Iteration 58400: loss = 1.519231, step_size = 0.141644, min_loss_found = 1.519141\n",
      "Iteration 58500: loss = 1.519244, step_size = 0.119724, min_loss_found = 1.519141\n",
      "Iteration 58600: loss = 1.519245, step_size = 0.148479, min_loss_found = 1.519141\n",
      "Iteration 58700: loss = 1.519282, step_size = 0.147017, min_loss_found = 1.519141\n",
      "Iteration 58800: loss = 1.519278, step_size = 0.153230, min_loss_found = 1.519141\n",
      "Iteration 58900: loss = 1.519204, step_size = 0.138812, min_loss_found = 1.519141\n",
      "Iteration 59000: loss = 1.519218, step_size = 0.128871, min_loss_found = 1.519141\n",
      "Iteration 59100: loss = 1.519367, step_size = 0.124798, min_loss_found = 1.519141\n",
      "Iteration 59200: loss = 1.519222, step_size = 0.190490, min_loss_found = 1.519141\n",
      "Iteration 59300: loss = 1.519368, step_size = 0.135754, min_loss_found = 1.519141\n",
      "Iteration 59400: loss = 1.519284, step_size = 0.124582, min_loss_found = 1.519141\n",
      "Iteration 59500: loss = 1.519277, step_size = 0.119343, min_loss_found = 1.519141\n",
      "Iteration 59600: loss = 1.519340, step_size = 0.159949, min_loss_found = 1.519141\n",
      "Iteration 59700: loss = 1.519260, step_size = 0.122392, min_loss_found = 1.519141\n",
      "Iteration 59800: loss = 1.519292, step_size = 0.128430, min_loss_found = 1.519141\n",
      "Iteration 59900: loss = 1.519403, step_size = 0.138333, min_loss_found = 1.519141\n",
      "Iteration 60000: loss = 1.519337, step_size = 0.217937, min_loss_found = 1.519141\n",
      "Iteration 60100: loss = 1.519338, step_size = 0.189529, min_loss_found = 1.519141\n",
      "Iteration 60200: loss = 1.519261, step_size = 0.125259, min_loss_found = 1.519141\n",
      "Iteration 60300: loss = 1.519313, step_size = 0.151454, min_loss_found = 1.519141\n",
      "Iteration 60400: loss = 1.519279, step_size = 0.127641, min_loss_found = 1.519141\n",
      "Iteration 60500: loss = 1.519229, step_size = 0.124243, min_loss_found = 1.519141\n",
      "Iteration 60600: loss = 1.519318, step_size = 0.130809, min_loss_found = 1.519141\n",
      "Iteration 60700: loss = 1.519410, step_size = 0.139966, min_loss_found = 1.519141\n",
      "Iteration 60800: loss = 1.519331, step_size = 0.155257, min_loss_found = 1.519141\n",
      "Iteration 60900: loss = 1.519316, step_size = 0.136722, min_loss_found = 1.519141\n",
      "Iteration 61000: loss = 1.519209, step_size = 0.134452, min_loss_found = 1.519141\n",
      "Iteration 61100: loss = 1.519383, step_size = 0.225810, min_loss_found = 1.519141\n",
      "Iteration 61200: loss = 1.519395, step_size = 0.166102, min_loss_found = 1.519141\n",
      "Iteration 61300: loss = 1.519369, step_size = 0.136261, min_loss_found = 1.519141\n",
      "Iteration 61400: loss = 1.519358, step_size = 0.161899, min_loss_found = 1.519141\n",
      "Iteration 61500: loss = 1.519389, step_size = 0.165850, min_loss_found = 1.519141\n",
      "Iteration 61600: loss = 1.519333, step_size = 0.126043, min_loss_found = 1.519141\n",
      "Iteration 61700: loss = 1.519324, step_size = 0.130343, min_loss_found = 1.519141\n",
      "Iteration 61800: loss = 1.519432, step_size = 0.229225, min_loss_found = 1.519141\n",
      "Iteration 61900: loss = 1.519298, step_size = 0.150789, min_loss_found = 1.519141\n",
      "Iteration 62000: loss = 1.519379, step_size = 0.175170, min_loss_found = 1.519141\n",
      "Iteration 62100: loss = 1.519261, step_size = 0.149871, min_loss_found = 1.519141\n",
      "Iteration 62200: loss = 1.519242, step_size = 0.200759, min_loss_found = 1.519141\n",
      "Iteration 62300: loss = 1.519271, step_size = 0.207801, min_loss_found = 1.519141\n",
      "Iteration 62400: loss = 1.519444, step_size = 0.159738, min_loss_found = 1.519141\n",
      "Iteration 62500: loss = 1.519256, step_size = 0.124326, min_loss_found = 1.519141\n",
      "Iteration 62600: loss = 1.519313, step_size = 0.152768, min_loss_found = 1.519141\n",
      "Iteration 62700: loss = 1.519258, step_size = 0.125974, min_loss_found = 1.519141\n",
      "Iteration 62800: loss = 1.519360, step_size = 0.176172, min_loss_found = 1.519141\n",
      "Iteration 62900: loss = 1.519214, step_size = 0.132355, min_loss_found = 1.519141\n",
      "Iteration 63000: loss = 1.519249, step_size = 0.120325, min_loss_found = 1.519141\n",
      "Iteration 63100: loss = 1.519278, step_size = 0.146534, min_loss_found = 1.519141\n",
      "Iteration 63200: loss = 1.519373, step_size = 0.163497, min_loss_found = 1.519141\n",
      "Iteration 63300: loss = 1.519388, step_size = 0.137087, min_loss_found = 1.519141\n",
      "Iteration 63400: loss = 1.519266, step_size = 0.148576, min_loss_found = 1.519141\n",
      "Iteration 63500: loss = 1.519302, step_size = 0.150535, min_loss_found = 1.519141\n",
      "Iteration 63600: loss = 1.519308, step_size = 0.150921, min_loss_found = 1.519141\n",
      "Iteration 63700: loss = 1.519286, step_size = 0.138163, min_loss_found = 1.519141\n",
      "Iteration 63800: loss = 1.519345, step_size = 0.237124, min_loss_found = 1.519141\n",
      "Iteration 63900: loss = 1.519284, step_size = 0.218146, min_loss_found = 1.519141\n",
      "Iteration 64000: loss = 1.519404, step_size = 0.135619, min_loss_found = 1.519141\n",
      "Iteration 64100: loss = 1.519327, step_size = 0.132181, min_loss_found = 1.519141\n",
      "Iteration 64200: loss = 1.519309, step_size = 0.155141, min_loss_found = 1.519141\n",
      "Iteration 64300: loss = 1.519317, step_size = 0.212044, min_loss_found = 1.519141\n",
      "Iteration 64400: loss = 1.519407, step_size = 0.147424, min_loss_found = 1.519141\n",
      "Iteration 64500: loss = 1.519312, step_size = 0.127801, min_loss_found = 1.519141\n",
      "Iteration 64600: loss = 1.519224, step_size = 0.178175, min_loss_found = 1.519140\n",
      "Iteration 64700: loss = 1.519339, step_size = 0.146337, min_loss_found = 1.519140\n",
      "Iteration 64800: loss = 1.519220, step_size = 0.211351, min_loss_found = 1.519140\n",
      "Iteration 64900: loss = 1.519177, step_size = 0.118442, min_loss_found = 1.519140\n",
      "Iteration 65000: loss = 1.519355, step_size = 0.157190, min_loss_found = 1.519140\n",
      "Iteration 65100: loss = 1.519330, step_size = 0.158340, min_loss_found = 1.519140\n",
      "Iteration 65200: loss = 1.519441, step_size = 0.171185, min_loss_found = 1.519140\n",
      "Iteration 65300: loss = 1.519452, step_size = 0.161355, min_loss_found = 1.519140\n",
      "Iteration 65400: loss = 1.519177, step_size = 0.176064, min_loss_found = 1.519140\n",
      "Iteration 65500: loss = 1.519244, step_size = 0.122572, min_loss_found = 1.519140\n",
      "Iteration 65600: loss = 1.519386, step_size = 0.163623, min_loss_found = 1.519140\n",
      "Iteration 65700: loss = 1.519324, step_size = 0.132067, min_loss_found = 1.519140\n",
      "Iteration 65800: loss = 1.519339, step_size = 0.154158, min_loss_found = 1.519140\n",
      "Iteration 65900: loss = 1.519348, step_size = 0.222905, min_loss_found = 1.519140\n",
      "Iteration 66000: loss = 1.519386, step_size = 0.161379, min_loss_found = 1.519140\n",
      "Iteration 66100: loss = 1.519296, step_size = 0.154061, min_loss_found = 1.519140\n",
      "Iteration 66200: loss = 1.519298, step_size = 0.170069, min_loss_found = 1.519140\n",
      "Iteration 66300: loss = 1.519388, step_size = 0.131815, min_loss_found = 1.519140\n",
      "Iteration 66400: loss = 1.519243, step_size = 0.201739, min_loss_found = 1.519140\n",
      "Iteration 66500: loss = 1.519366, step_size = 0.158813, min_loss_found = 1.519140\n",
      "Iteration 66600: loss = 1.519339, step_size = 0.190358, min_loss_found = 1.519140\n",
      "Iteration 66700: loss = 1.519158, step_size = 0.165082, min_loss_found = 1.519140\n",
      "Iteration 66800: loss = 1.519328, step_size = 0.121416, min_loss_found = 1.519140\n",
      "Iteration 66900: loss = 1.519326, step_size = 0.147891, min_loss_found = 1.519140\n",
      "Iteration 67000: loss = 1.519290, step_size = 0.208030, min_loss_found = 1.519140\n",
      "Iteration 67100: loss = 1.519188, step_size = 0.124311, min_loss_found = 1.519140\n",
      "Iteration 67200: loss = 1.519191, step_size = 0.168335, min_loss_found = 1.519140\n",
      "Iteration 67300: loss = 1.519273, step_size = 0.125631, min_loss_found = 1.519140\n",
      "Iteration 67400: loss = 1.519334, step_size = 0.229664, min_loss_found = 1.519140\n",
      "Iteration 67500: loss = 1.519230, step_size = 0.138485, min_loss_found = 1.519140\n",
      "Iteration 67600: loss = 1.519237, step_size = 0.179877, min_loss_found = 1.519140\n",
      "Iteration 67700: loss = 1.519287, step_size = 0.233765, min_loss_found = 1.519140\n",
      "Iteration 67800: loss = 1.519358, step_size = 0.137044, min_loss_found = 1.519140\n",
      "Iteration 67900: loss = 1.519272, step_size = 0.130249, min_loss_found = 1.519140\n",
      "Iteration 68000: loss = 1.519325, step_size = 0.163168, min_loss_found = 1.519128\n",
      "Iteration 68100: loss = 1.519292, step_size = 0.200110, min_loss_found = 1.519128\n",
      "Iteration 68200: loss = 1.519221, step_size = 0.117932, min_loss_found = 1.519128\n",
      "Iteration 68300: loss = 1.519306, step_size = 0.160945, min_loss_found = 1.519128\n",
      "Iteration 68400: loss = 1.519402, step_size = 0.138822, min_loss_found = 1.519128\n",
      "Iteration 68500: loss = 1.519288, step_size = 0.143662, min_loss_found = 1.519128\n",
      "Iteration 68600: loss = 1.519344, step_size = 0.122811, min_loss_found = 1.519128\n",
      "Iteration 68700: loss = 1.519199, step_size = 0.156132, min_loss_found = 1.519128\n",
      "Iteration 68800: loss = 1.519187, step_size = 0.127004, min_loss_found = 1.519128\n",
      "Iteration 68900: loss = 1.519308, step_size = 0.116427, min_loss_found = 1.519128\n",
      "Iteration 69000: loss = 1.519313, step_size = 0.185487, min_loss_found = 1.519128\n",
      "Iteration 69100: loss = 1.519354, step_size = 0.158676, min_loss_found = 1.519128\n",
      "Iteration 69200: loss = 1.519272, step_size = 0.208876, min_loss_found = 1.519128\n",
      "Iteration 69300: loss = 1.519385, step_size = 0.202595, min_loss_found = 1.519128\n",
      "Iteration 69400: loss = 1.519293, step_size = 0.157149, min_loss_found = 1.519128\n",
      "Iteration 69500: loss = 1.519253, step_size = 0.123368, min_loss_found = 1.519128\n",
      "Iteration 69600: loss = 1.519344, step_size = 0.119359, min_loss_found = 1.519128\n",
      "Iteration 69700: loss = 1.519373, step_size = 0.156086, min_loss_found = 1.519128\n",
      "Iteration 69800: loss = 1.519367, step_size = 0.144239, min_loss_found = 1.519128\n",
      "Iteration 69900: loss = 1.519257, step_size = 0.137760, min_loss_found = 1.519128\n",
      "Iteration 70000: loss = 1.519258, step_size = 0.148099, min_loss_found = 1.519128\n",
      "Iteration 70100: loss = 1.519240, step_size = 0.185409, min_loss_found = 1.519128\n",
      "Iteration 70200: loss = 1.519325, step_size = 0.215231, min_loss_found = 1.519128\n",
      "Iteration 70300: loss = 1.519283, step_size = 0.182191, min_loss_found = 1.519128\n",
      "Iteration 70400: loss = 1.519199, step_size = 0.139926, min_loss_found = 1.519128\n",
      "Iteration 70500: loss = 1.519326, step_size = 0.132275, min_loss_found = 1.519128\n",
      "Iteration 70600: loss = 1.519239, step_size = 0.151763, min_loss_found = 1.519128\n",
      "Iteration 70700: loss = 1.519249, step_size = 0.148573, min_loss_found = 1.519124\n",
      "Iteration 70800: loss = 1.519215, step_size = 0.196714, min_loss_found = 1.519124\n",
      "Iteration 70900: loss = 1.519363, step_size = 0.135693, min_loss_found = 1.519124\n",
      "Iteration 71000: loss = 1.519297, step_size = 0.189405, min_loss_found = 1.519124\n",
      "Iteration 71100: loss = 1.519336, step_size = 0.139119, min_loss_found = 1.519124\n",
      "Iteration 71200: loss = 1.519343, step_size = 0.133864, min_loss_found = 1.519124\n",
      "Iteration 71300: loss = 1.519199, step_size = 0.180922, min_loss_found = 1.519124\n",
      "Iteration 71400: loss = 1.519246, step_size = 0.188338, min_loss_found = 1.519124\n",
      "Iteration 71500: loss = 1.519300, step_size = 0.152319, min_loss_found = 1.519124\n",
      "Iteration 71600: loss = 1.519257, step_size = 0.202846, min_loss_found = 1.519124\n",
      "Iteration 71700: loss = 1.519382, step_size = 0.136934, min_loss_found = 1.519124\n",
      "Iteration 71800: loss = 1.519228, step_size = 0.118892, min_loss_found = 1.519124\n",
      "Iteration 71900: loss = 1.519351, step_size = 0.157715, min_loss_found = 1.519124\n",
      "Iteration 72000: loss = 1.519219, step_size = 0.199178, min_loss_found = 1.519124\n",
      "Iteration 72100: loss = 1.519219, step_size = 0.114939, min_loss_found = 1.519124\n",
      "Iteration 72200: loss = 1.519259, step_size = 0.147051, min_loss_found = 1.519124\n",
      "Iteration 72300: loss = 1.519276, step_size = 0.184825, min_loss_found = 1.519124\n",
      "Iteration 72400: loss = 1.519290, step_size = 0.141240, min_loss_found = 1.519124\n",
      "Iteration 72500: loss = 1.519448, step_size = 0.147838, min_loss_found = 1.519124\n",
      "Iteration 72600: loss = 1.519207, step_size = 0.139172, min_loss_found = 1.519124\n",
      "Iteration 72700: loss = 1.519210, step_size = 0.139542, min_loss_found = 1.519124\n",
      "Iteration 72800: loss = 1.519232, step_size = 0.194330, min_loss_found = 1.519124\n",
      "Iteration 72900: loss = 1.519281, step_size = 0.153338, min_loss_found = 1.519124\n",
      "Iteration 73000: loss = 1.519316, step_size = 0.157313, min_loss_found = 1.519124\n",
      "Iteration 73100: loss = 1.519237, step_size = 0.148426, min_loss_found = 1.519124\n",
      "Iteration 73200: loss = 1.519268, step_size = 0.125921, min_loss_found = 1.519124\n",
      "Iteration 73300: loss = 1.519284, step_size = 0.121195, min_loss_found = 1.519124\n",
      "Iteration 73400: loss = 1.519265, step_size = 0.116058, min_loss_found = 1.519124\n",
      "Iteration 73500: loss = 1.519274, step_size = 0.160454, min_loss_found = 1.519124\n",
      "Iteration 73600: loss = 1.519462, step_size = 0.144801, min_loss_found = 1.519124\n",
      "Iteration 73700: loss = 1.519240, step_size = 0.200623, min_loss_found = 1.519124\n",
      "Iteration 73800: loss = 1.519340, step_size = 0.158521, min_loss_found = 1.519124\n",
      "Iteration 73900: loss = 1.519345, step_size = 0.204607, min_loss_found = 1.519124\n",
      "Iteration 74000: loss = 1.519280, step_size = 0.160136, min_loss_found = 1.519124\n",
      "Iteration 74100: loss = 1.519321, step_size = 0.211293, min_loss_found = 1.519124\n",
      "Iteration 74200: loss = 1.519326, step_size = 0.179660, min_loss_found = 1.519124\n",
      "Iteration 74300: loss = 1.519187, step_size = 0.195551, min_loss_found = 1.519124\n",
      "Iteration 74400: loss = 1.519263, step_size = 0.196381, min_loss_found = 1.519124\n",
      "Iteration 74500: loss = 1.519348, step_size = 0.158227, min_loss_found = 1.519124\n",
      "Iteration 74600: loss = 1.519330, step_size = 0.139904, min_loss_found = 1.519124\n",
      "Iteration 74700: loss = 1.519225, step_size = 0.201311, min_loss_found = 1.519124\n",
      "Iteration 74800: loss = 1.519230, step_size = 0.218335, min_loss_found = 1.519124\n",
      "Iteration 74900: loss = 1.519260, step_size = 0.116315, min_loss_found = 1.519124\n",
      "Iteration 75000: loss = 1.519269, step_size = 0.157047, min_loss_found = 1.519124\n",
      "Iteration 75100: loss = 1.519288, step_size = 0.139765, min_loss_found = 1.519124\n",
      "Iteration 75200: loss = 1.519371, step_size = 0.160201, min_loss_found = 1.519116\n",
      "Iteration 75300: loss = 1.519279, step_size = 0.151354, min_loss_found = 1.519116\n",
      "Iteration 75400: loss = 1.519426, step_size = 0.146842, min_loss_found = 1.519116\n",
      "Iteration 75500: loss = 1.519302, step_size = 0.149727, min_loss_found = 1.519116\n",
      "Iteration 75600: loss = 1.519315, step_size = 0.147098, min_loss_found = 1.519116\n",
      "Iteration 75700: loss = 1.519332, step_size = 0.187610, min_loss_found = 1.519116\n",
      "Iteration 75800: loss = 1.519284, step_size = 0.119444, min_loss_found = 1.519116\n",
      "Iteration 75900: loss = 1.519244, step_size = 0.111110, min_loss_found = 1.519116\n",
      "Iteration 76000: loss = 1.519324, step_size = 0.205149, min_loss_found = 1.519116\n",
      "Iteration 76100: loss = 1.519324, step_size = 0.210556, min_loss_found = 1.519116\n",
      "Iteration 76200: loss = 1.519264, step_size = 0.150197, min_loss_found = 1.519116\n",
      "Iteration 76300: loss = 1.519314, step_size = 0.130806, min_loss_found = 1.519116\n",
      "Iteration 76400: loss = 1.519314, step_size = 0.153758, min_loss_found = 1.519116\n",
      "Iteration 76500: loss = 1.519310, step_size = 0.208763, min_loss_found = 1.519116\n",
      "Iteration 76600: loss = 1.519266, step_size = 0.145441, min_loss_found = 1.519116\n",
      "Iteration 76700: loss = 1.519309, step_size = 0.208526, min_loss_found = 1.519116\n",
      "Iteration 76800: loss = 1.519199, step_size = 0.143027, min_loss_found = 1.519116\n",
      "Iteration 76900: loss = 1.519210, step_size = 0.183353, min_loss_found = 1.519116\n",
      "Iteration 77000: loss = 1.519400, step_size = 0.131902, min_loss_found = 1.519116\n",
      "Iteration 77100: loss = 1.519240, step_size = 0.148879, min_loss_found = 1.519116\n",
      "Iteration 77200: loss = 1.519363, step_size = 0.138867, min_loss_found = 1.519116\n",
      "Iteration 77300: loss = 1.519255, step_size = 0.179133, min_loss_found = 1.519116\n",
      "Iteration 77400: loss = 1.519267, step_size = 0.195579, min_loss_found = 1.519116\n",
      "Iteration 77500: loss = 1.519147, step_size = 0.111310, min_loss_found = 1.519116\n",
      "Iteration 77600: loss = 1.519282, step_size = 0.210411, min_loss_found = 1.519116\n",
      "Iteration 77700: loss = 1.519248, step_size = 0.155088, min_loss_found = 1.519116\n",
      "Iteration 77800: loss = 1.519263, step_size = 0.137275, min_loss_found = 1.519116\n",
      "Iteration 77900: loss = 1.519219, step_size = 0.184609, min_loss_found = 1.519116\n",
      "Iteration 78000: loss = 1.519259, step_size = 0.154859, min_loss_found = 1.519116\n",
      "Iteration 78100: loss = 1.519244, step_size = 0.149183, min_loss_found = 1.519116\n",
      "Iteration 78200: loss = 1.519326, step_size = 0.213940, min_loss_found = 1.519116\n",
      "Iteration 78300: loss = 1.519227, step_size = 0.145996, min_loss_found = 1.519116\n",
      "Iteration 78400: loss = 1.519265, step_size = 0.177225, min_loss_found = 1.519116\n",
      "Iteration 78500: loss = 1.519265, step_size = 0.118897, min_loss_found = 1.519116\n",
      "Iteration 78600: loss = 1.519258, step_size = 0.146852, min_loss_found = 1.519116\n",
      "Iteration 78700: loss = 1.519293, step_size = 0.128975, min_loss_found = 1.519116\n",
      "Iteration 78800: loss = 1.519392, step_size = 0.126820, min_loss_found = 1.519116\n",
      "Iteration 78900: loss = 1.519250, step_size = 0.169297, min_loss_found = 1.519116\n",
      "Iteration 79000: loss = 1.519327, step_size = 0.212960, min_loss_found = 1.519116\n",
      "Iteration 79100: loss = 1.519269, step_size = 0.183811, min_loss_found = 1.519116\n",
      "Iteration 79200: loss = 1.519299, step_size = 0.120729, min_loss_found = 1.519116\n",
      "Iteration 79300: loss = 1.519322, step_size = 0.155462, min_loss_found = 1.519116\n",
      "Iteration 79400: loss = 1.519233, step_size = 0.142968, min_loss_found = 1.519116\n",
      "Iteration 79500: loss = 1.519292, step_size = 0.122785, min_loss_found = 1.519116\n",
      "Iteration 79600: loss = 1.519317, step_size = 0.137308, min_loss_found = 1.519116\n",
      "Iteration 79700: loss = 1.519188, step_size = 0.196077, min_loss_found = 1.519116\n",
      "Iteration 79800: loss = 1.519288, step_size = 0.148485, min_loss_found = 1.519116\n",
      "Iteration 79900: loss = 1.519369, step_size = 0.159693, min_loss_found = 1.519116\n",
      "Iteration 80000: loss = 1.519308, step_size = 0.191396, min_loss_found = 1.519116\n",
      "Iteration 80100: loss = 1.519317, step_size = 0.169613, min_loss_found = 1.519116\n",
      "Iteration 80200: loss = 1.519396, step_size = 0.162520, min_loss_found = 1.519116\n",
      "Iteration 80300: loss = 1.519226, step_size = 0.146752, min_loss_found = 1.519115\n",
      "Iteration 80400: loss = 1.519268, step_size = 0.190865, min_loss_found = 1.519115\n",
      "Iteration 80500: loss = 1.519176, step_size = 0.125352, min_loss_found = 1.519115\n",
      "Iteration 80600: loss = 1.519237, step_size = 0.145855, min_loss_found = 1.519115\n",
      "Iteration 80700: loss = 1.519417, step_size = 0.159583, min_loss_found = 1.519115\n",
      "Iteration 80800: loss = 1.519171, step_size = 0.190204, min_loss_found = 1.519115\n",
      "Iteration 80900: loss = 1.519301, step_size = 0.212830, min_loss_found = 1.519115\n",
      "Iteration 81000: loss = 1.519154, step_size = 0.134263, min_loss_found = 1.519115\n",
      "Iteration 81100: loss = 1.519326, step_size = 0.156982, min_loss_found = 1.519115\n",
      "Iteration 81200: loss = 1.519386, step_size = 0.133036, min_loss_found = 1.519115\n",
      "Iteration 81300: loss = 1.519220, step_size = 0.121939, min_loss_found = 1.519115\n",
      "Iteration 81400: loss = 1.519301, step_size = 0.155461, min_loss_found = 1.519115\n",
      "Iteration 81500: loss = 1.519212, step_size = 0.138802, min_loss_found = 1.519115\n",
      "Iteration 81600: loss = 1.519232, step_size = 0.135140, min_loss_found = 1.519115\n",
      "Iteration 81700: loss = 1.519137, step_size = 0.119455, min_loss_found = 1.519115\n",
      "Iteration 81800: loss = 1.519272, step_size = 0.163918, min_loss_found = 1.519115\n",
      "Iteration 81900: loss = 1.519375, step_size = 0.148535, min_loss_found = 1.519115\n",
      "Iteration 82000: loss = 1.519280, step_size = 0.133710, min_loss_found = 1.519115\n",
      "Iteration 82100: loss = 1.519190, step_size = 0.147856, min_loss_found = 1.519115\n",
      "Iteration 82200: loss = 1.519152, step_size = 0.149889, min_loss_found = 1.519115\n",
      "Iteration 82300: loss = 1.519204, step_size = 0.123582, min_loss_found = 1.519115\n",
      "Iteration 82400: loss = 1.519304, step_size = 0.139825, min_loss_found = 1.519115\n",
      "Iteration 82500: loss = 1.519208, step_size = 0.123420, min_loss_found = 1.519115\n",
      "Iteration 82600: loss = 1.519392, step_size = 0.220787, min_loss_found = 1.519115\n",
      "Iteration 82700: loss = 1.519242, step_size = 0.173638, min_loss_found = 1.519115\n",
      "Iteration 82800: loss = 1.519240, step_size = 0.155439, min_loss_found = 1.519115\n",
      "Iteration 82900: loss = 1.519293, step_size = 0.228643, min_loss_found = 1.519115\n",
      "Iteration 83000: loss = 1.519174, step_size = 0.136431, min_loss_found = 1.519115\n",
      "Iteration 83100: loss = 1.519214, step_size = 0.143544, min_loss_found = 1.519115\n",
      "Iteration 83200: loss = 1.519258, step_size = 0.136093, min_loss_found = 1.519115\n",
      "Iteration 83300: loss = 1.519220, step_size = 0.119058, min_loss_found = 1.519115\n",
      "Iteration 83400: loss = 1.519325, step_size = 0.142049, min_loss_found = 1.519115\n",
      "Iteration 83500: loss = 1.519223, step_size = 0.146809, min_loss_found = 1.519115\n",
      "Iteration 83600: loss = 1.519319, step_size = 0.144882, min_loss_found = 1.519115\n",
      "Iteration 83700: loss = 1.519285, step_size = 0.117710, min_loss_found = 1.519115\n",
      "Iteration 83800: loss = 1.519319, step_size = 0.153825, min_loss_found = 1.519115\n",
      "Iteration 83900: loss = 1.519423, step_size = 0.154740, min_loss_found = 1.519115\n",
      "Iteration 84000: loss = 1.519306, step_size = 0.145755, min_loss_found = 1.519115\n",
      "Iteration 84100: loss = 1.519174, step_size = 0.120819, min_loss_found = 1.519115\n",
      "Iteration 84200: loss = 1.519400, step_size = 0.162577, min_loss_found = 1.519115\n",
      "Iteration 84300: loss = 1.519344, step_size = 0.156544, min_loss_found = 1.519115\n",
      "Iteration 84400: loss = 1.519249, step_size = 0.183286, min_loss_found = 1.519115\n",
      "Iteration 84500: loss = 1.519222, step_size = 0.185087, min_loss_found = 1.519115\n",
      "Iteration 84600: loss = 1.519390, step_size = 0.150026, min_loss_found = 1.519115\n",
      "Iteration 84700: loss = 1.519271, step_size = 0.132284, min_loss_found = 1.519115\n",
      "Iteration 84800: loss = 1.519230, step_size = 0.160353, min_loss_found = 1.519115\n",
      "Iteration 84900: loss = 1.519301, step_size = 0.119794, min_loss_found = 1.519115\n",
      "Iteration 85000: loss = 1.519348, step_size = 0.216750, min_loss_found = 1.519115\n",
      "Iteration 85100: loss = 1.519395, step_size = 0.134417, min_loss_found = 1.519115\n",
      "Iteration 85200: loss = 1.519223, step_size = 0.141162, min_loss_found = 1.519115\n",
      "Iteration 85300: loss = 1.519339, step_size = 0.209417, min_loss_found = 1.519115\n",
      "Iteration 85400: loss = 1.519227, step_size = 0.141493, min_loss_found = 1.519115\n",
      "Iteration 85500: loss = 1.519255, step_size = 0.149113, min_loss_found = 1.519115\n",
      "Iteration 85600: loss = 1.519249, step_size = 0.120764, min_loss_found = 1.519114\n",
      "Iteration 85700: loss = 1.519258, step_size = 0.118904, min_loss_found = 1.519114\n",
      "Iteration 85800: loss = 1.519175, step_size = 0.124684, min_loss_found = 1.519100\n",
      "Iteration 85900: loss = 1.519257, step_size = 0.150576, min_loss_found = 1.519100\n",
      "Iteration 86000: loss = 1.519359, step_size = 0.157895, min_loss_found = 1.519100\n",
      "Iteration 86100: loss = 1.519357, step_size = 0.134605, min_loss_found = 1.519100\n",
      "Iteration 86200: loss = 1.519274, step_size = 0.130397, min_loss_found = 1.519100\n",
      "Iteration 86300: loss = 1.519261, step_size = 0.138186, min_loss_found = 1.519100\n",
      "Iteration 86400: loss = 1.519226, step_size = 0.193118, min_loss_found = 1.519100\n",
      "Iteration 86500: loss = 1.519172, step_size = 0.113112, min_loss_found = 1.519100\n",
      "Iteration 86600: loss = 1.519206, step_size = 0.196774, min_loss_found = 1.519100\n",
      "Iteration 86700: loss = 1.519283, step_size = 0.133740, min_loss_found = 1.519100\n",
      "Iteration 86800: loss = 1.519313, step_size = 0.123024, min_loss_found = 1.519100\n",
      "Iteration 86900: loss = 1.519331, step_size = 0.194964, min_loss_found = 1.519100\n",
      "Iteration 87000: loss = 1.519195, step_size = 0.193521, min_loss_found = 1.519100\n",
      "Iteration 87100: loss = 1.519325, step_size = 0.185298, min_loss_found = 1.519100\n",
      "Iteration 87200: loss = 1.519263, step_size = 0.164358, min_loss_found = 1.519100\n",
      "Iteration 87300: loss = 1.519250, step_size = 0.204520, min_loss_found = 1.519100\n",
      "Iteration 87400: loss = 1.519208, step_size = 0.138971, min_loss_found = 1.519100\n",
      "Iteration 87500: loss = 1.519286, step_size = 0.126782, min_loss_found = 1.519100\n",
      "Iteration 87600: loss = 1.519281, step_size = 0.152097, min_loss_found = 1.519100\n",
      "Iteration 87700: loss = 1.519214, step_size = 0.169392, min_loss_found = 1.519100\n",
      "Iteration 87800: loss = 1.519257, step_size = 0.122332, min_loss_found = 1.519100\n",
      "Iteration 87900: loss = 1.519333, step_size = 0.188602, min_loss_found = 1.519100\n",
      "Iteration 88000: loss = 1.519340, step_size = 0.128489, min_loss_found = 1.519100\n",
      "Iteration 88100: loss = 1.519114, step_size = 0.181745, min_loss_found = 1.519100\n",
      "Iteration 88200: loss = 1.519308, step_size = 0.164950, min_loss_found = 1.519100\n",
      "Iteration 88300: loss = 1.519207, step_size = 0.132753, min_loss_found = 1.519100\n",
      "Iteration 88400: loss = 1.519246, step_size = 0.202257, min_loss_found = 1.519100\n",
      "Iteration 88500: loss = 1.519227, step_size = 0.163522, min_loss_found = 1.519100\n",
      "Iteration 88600: loss = 1.519221, step_size = 0.120979, min_loss_found = 1.519100\n",
      "Iteration 88700: loss = 1.519179, step_size = 0.188978, min_loss_found = 1.519100\n",
      "Iteration 88800: loss = 1.519156, step_size = 0.140331, min_loss_found = 1.519100\n",
      "Iteration 88900: loss = 1.519336, step_size = 0.152634, min_loss_found = 1.519100\n",
      "Iteration 89000: loss = 1.519343, step_size = 0.146407, min_loss_found = 1.519100\n",
      "Iteration 89100: loss = 1.519263, step_size = 0.129176, min_loss_found = 1.519100\n",
      "Iteration 89200: loss = 1.519368, step_size = 0.149043, min_loss_found = 1.519100\n",
      "Iteration 89300: loss = 1.519256, step_size = 0.125663, min_loss_found = 1.519100\n",
      "Iteration 89400: loss = 1.519271, step_size = 0.230839, min_loss_found = 1.519100\n",
      "Iteration 89500: loss = 1.519206, step_size = 0.145003, min_loss_found = 1.519100\n",
      "Iteration 89600: loss = 1.519262, step_size = 0.149156, min_loss_found = 1.519100\n",
      "Iteration 89700: loss = 1.519345, step_size = 0.156518, min_loss_found = 1.519100\n",
      "Iteration 89800: loss = 1.519241, step_size = 0.177311, min_loss_found = 1.519100\n",
      "Iteration 89900: loss = 1.519293, step_size = 0.164458, min_loss_found = 1.519100\n",
      "Iteration 90000: loss = 1.519310, step_size = 0.158883, min_loss_found = 1.519100\n",
      "Iteration 90100: loss = 1.519262, step_size = 0.138238, min_loss_found = 1.519100\n",
      "Iteration 90200: loss = 1.519266, step_size = 0.150351, min_loss_found = 1.519100\n",
      "Iteration 90300: loss = 1.519351, step_size = 0.174260, min_loss_found = 1.519100\n",
      "Iteration 90400: loss = 1.519242, step_size = 0.182940, min_loss_found = 1.519100\n",
      "Iteration 90500: loss = 1.519193, step_size = 0.143536, min_loss_found = 1.519100\n",
      "Iteration 90600: loss = 1.519273, step_size = 0.192216, min_loss_found = 1.519100\n",
      "Iteration 90700: loss = 1.519197, step_size = 0.155709, min_loss_found = 1.519100\n",
      "Iteration 90800: loss = 1.519333, step_size = 0.162130, min_loss_found = 1.519100\n",
      "Iteration 90900: loss = 1.519288, step_size = 0.128655, min_loss_found = 1.519100\n",
      "Iteration 91000: loss = 1.519174, step_size = 0.138492, min_loss_found = 1.519100\n",
      "Iteration 91100: loss = 1.519351, step_size = 0.162884, min_loss_found = 1.519100\n",
      "Iteration 91200: loss = 1.519348, step_size = 0.133201, min_loss_found = 1.519100\n",
      "Iteration 91300: loss = 1.519288, step_size = 0.152318, min_loss_found = 1.519100\n",
      "Iteration 91400: loss = 1.519283, step_size = 0.153410, min_loss_found = 1.519100\n",
      "Iteration 91500: loss = 1.519398, step_size = 0.144683, min_loss_found = 1.519100\n",
      "Iteration 91600: loss = 1.519181, step_size = 0.110955, min_loss_found = 1.519100\n",
      "Iteration 91700: loss = 1.519175, step_size = 0.180478, min_loss_found = 1.519100\n",
      "Iteration 91800: loss = 1.519291, step_size = 0.134234, min_loss_found = 1.519100\n",
      "Iteration 91900: loss = 1.519236, step_size = 0.163889, min_loss_found = 1.519100\n",
      "Iteration 92000: loss = 1.519403, step_size = 0.215516, min_loss_found = 1.519100\n",
      "Iteration 92100: loss = 1.519310, step_size = 0.128167, min_loss_found = 1.519085\n",
      "Iteration 92200: loss = 1.519222, step_size = 0.134360, min_loss_found = 1.519085\n",
      "Iteration 92300: loss = 1.519221, step_size = 0.183881, min_loss_found = 1.519085\n",
      "Iteration 92400: loss = 1.519190, step_size = 0.206488, min_loss_found = 1.519085\n",
      "Iteration 92500: loss = 1.519194, step_size = 0.217955, min_loss_found = 1.519085\n",
      "Iteration 92600: loss = 1.519270, step_size = 0.133878, min_loss_found = 1.519085\n",
      "Iteration 92700: loss = 1.519265, step_size = 0.131907, min_loss_found = 1.519085\n",
      "Iteration 92800: loss = 1.519208, step_size = 0.126346, min_loss_found = 1.519085\n",
      "Iteration 92900: loss = 1.519170, step_size = 0.114824, min_loss_found = 1.519085\n",
      "Iteration 93000: loss = 1.519267, step_size = 0.149395, min_loss_found = 1.519085\n",
      "Iteration 93100: loss = 1.519221, step_size = 0.112279, min_loss_found = 1.519085\n",
      "Iteration 93200: loss = 1.519230, step_size = 0.199788, min_loss_found = 1.519085\n",
      "Iteration 93300: loss = 1.519237, step_size = 0.115741, min_loss_found = 1.519085\n",
      "Iteration 93400: loss = 1.519286, step_size = 0.143315, min_loss_found = 1.519085\n",
      "Iteration 93500: loss = 1.519387, step_size = 0.144107, min_loss_found = 1.519085\n",
      "Iteration 93600: loss = 1.519201, step_size = 0.193421, min_loss_found = 1.519085\n",
      "Iteration 93700: loss = 1.519192, step_size = 0.147839, min_loss_found = 1.519085\n",
      "Iteration 93800: loss = 1.519263, step_size = 0.229609, min_loss_found = 1.519085\n",
      "Iteration 93900: loss = 1.519343, step_size = 0.148475, min_loss_found = 1.519085\n",
      "Iteration 94000: loss = 1.519187, step_size = 0.124325, min_loss_found = 1.519085\n",
      "Iteration 94100: loss = 1.519323, step_size = 0.204935, min_loss_found = 1.519085\n",
      "Iteration 94200: loss = 1.519215, step_size = 0.153445, min_loss_found = 1.519085\n",
      "Iteration 94300: loss = 1.519225, step_size = 0.207382, min_loss_found = 1.519085\n",
      "Iteration 94400: loss = 1.519330, step_size = 0.213995, min_loss_found = 1.519085\n",
      "Iteration 94500: loss = 1.519319, step_size = 0.154916, min_loss_found = 1.519085\n",
      "Iteration 94600: loss = 1.519282, step_size = 0.191326, min_loss_found = 1.519085\n",
      "Iteration 94700: loss = 1.519363, step_size = 0.156581, min_loss_found = 1.519085\n",
      "Iteration 94800: loss = 1.519211, step_size = 0.139822, min_loss_found = 1.519085\n",
      "Iteration 94900: loss = 1.519326, step_size = 0.127598, min_loss_found = 1.519085\n",
      "Iteration 95000: loss = 1.519298, step_size = 0.125716, min_loss_found = 1.519085\n",
      "Iteration 95100: loss = 1.519225, step_size = 0.126381, min_loss_found = 1.519085\n",
      "Iteration 95200: loss = 1.519235, step_size = 0.114148, min_loss_found = 1.519085\n",
      "Iteration 95300: loss = 1.519220, step_size = 0.145517, min_loss_found = 1.519085\n",
      "Iteration 95400: loss = 1.519186, step_size = 0.142692, min_loss_found = 1.519085\n",
      "Iteration 95500: loss = 1.519225, step_size = 0.112633, min_loss_found = 1.519085\n",
      "Iteration 95600: loss = 1.519243, step_size = 0.129566, min_loss_found = 1.519085\n",
      "Iteration 95700: loss = 1.519269, step_size = 0.143087, min_loss_found = 1.519085\n",
      "Iteration 95800: loss = 1.519225, step_size = 0.173511, min_loss_found = 1.519085\n",
      "Iteration 95900: loss = 1.519130, step_size = 0.116068, min_loss_found = 1.519085\n",
      "Iteration 96000: loss = 1.519214, step_size = 0.144155, min_loss_found = 1.519085\n",
      "Iteration 96100: loss = 1.519130, step_size = 0.135348, min_loss_found = 1.519085\n",
      "Iteration 96200: loss = 1.519245, step_size = 0.164389, min_loss_found = 1.519085\n",
      "Iteration 96300: loss = 1.519231, step_size = 0.145445, min_loss_found = 1.519085\n",
      "Iteration 96400: loss = 1.519219, step_size = 0.156060, min_loss_found = 1.519085\n",
      "Iteration 96500: loss = 1.519304, step_size = 0.159104, min_loss_found = 1.519085\n",
      "Iteration 96600: loss = 1.519145, step_size = 0.137103, min_loss_found = 1.519085\n",
      "Iteration 96700: loss = 1.519302, step_size = 0.147011, min_loss_found = 1.519085\n",
      "Iteration 96800: loss = 1.519286, step_size = 0.147356, min_loss_found = 1.519085\n",
      "Iteration 96900: loss = 1.519286, step_size = 0.140816, min_loss_found = 1.519085\n",
      "Iteration 97000: loss = 1.519287, step_size = 0.150617, min_loss_found = 1.519085\n",
      "Iteration 97100: loss = 1.519278, step_size = 0.120602, min_loss_found = 1.519085\n",
      "Iteration 97200: loss = 1.519173, step_size = 0.110793, min_loss_found = 1.519085\n",
      "Iteration 97300: loss = 1.519177, step_size = 0.156255, min_loss_found = 1.519085\n",
      "Iteration 97400: loss = 1.519383, step_size = 0.147860, min_loss_found = 1.519085\n",
      "Iteration 97500: loss = 1.519229, step_size = 0.220959, min_loss_found = 1.519085\n",
      "Iteration 97600: loss = 1.519235, step_size = 0.130527, min_loss_found = 1.519085\n",
      "Iteration 97700: loss = 1.519207, step_size = 0.141560, min_loss_found = 1.519085\n",
      "Iteration 97800: loss = 1.519169, step_size = 0.187452, min_loss_found = 1.519085\n",
      "Iteration 97900: loss = 1.519153, step_size = 0.119561, min_loss_found = 1.519085\n",
      "Iteration 98000: loss = 1.519305, step_size = 0.212646, min_loss_found = 1.519085\n",
      "Iteration 98100: loss = 1.519197, step_size = 0.127870, min_loss_found = 1.519085\n",
      "Iteration 98200: loss = 1.519316, step_size = 0.146636, min_loss_found = 1.519085\n",
      "Iteration 98300: loss = 1.519266, step_size = 0.160218, min_loss_found = 1.519085\n",
      "Iteration 98400: loss = 1.519329, step_size = 0.150162, min_loss_found = 1.519085\n",
      "Iteration 98500: loss = 1.519286, step_size = 0.159413, min_loss_found = 1.519085\n",
      "Iteration 98600: loss = 1.519285, step_size = 0.152358, min_loss_found = 1.519085\n",
      "Iteration 98700: loss = 1.519219, step_size = 0.184604, min_loss_found = 1.519085\n",
      "Iteration 98800: loss = 1.519250, step_size = 0.131775, min_loss_found = 1.519085\n",
      "Iteration 98900: loss = 1.519231, step_size = 0.153091, min_loss_found = 1.519085\n",
      "Iteration 99000: loss = 1.519330, step_size = 0.147087, min_loss_found = 1.519085\n",
      "Iteration 99100: loss = 1.519389, step_size = 0.141126, min_loss_found = 1.519085\n",
      "Iteration 99200: loss = 1.519249, step_size = 0.143898, min_loss_found = 1.519085\n",
      "Iteration 99300: loss = 1.519230, step_size = 0.134951, min_loss_found = 1.519085\n",
      "Iteration 99400: loss = 1.519188, step_size = 0.192527, min_loss_found = 1.519085\n",
      "Iteration 99500: loss = 1.519309, step_size = 0.146339, min_loss_found = 1.519085\n",
      "Iteration 99600: loss = 1.519317, step_size = 0.164431, min_loss_found = 1.519085\n",
      "Iteration 99700: loss = 1.519179, step_size = 0.189735, min_loss_found = 1.519085\n",
      "Iteration 99800: loss = 1.519249, step_size = 0.146372, min_loss_found = 1.519085\n",
      "Iteration 99900: loss = 1.519197, step_size = 0.142747, min_loss_found = 1.519085\n",
      "Final loss: 1.519245940708013\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAEWCAYAAAAD/hLkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAALEwAACxMBAJqcGAAAM1dJREFUeJzt3Ql4VOXZBuDnYZdFRBCURUFZFFGgxh1UXBCtS6vVSq22aqX217/aaq1WW2ulrdrWutQNq7V/i+JuRVFACyIurKLsCAgCIihI2GR//+s9+SZOhkkyIZPMnOS5r+tcmTnrNweSd77lfC/NDCIiInFVJ9cFEBERqQwFMhERiTUFMhERiTUFMhERiTUFMhERiTUFMhERiTUFMhEpFcmHSP461+UQKYsCmUiOkVxE8uQcXPdxkoNT1nUkaSTr+Xszu8LMbsvXzyDiFMhEJKcSQVNkVymQieQpkg1J3k3y07D464ZhWyuSL5NcQ3I1ybdIRr/PJH9JchnJdSTnkjwpG7W20q5J8l8A9gUwnOR6kteH/c8iOTPsP5bkQSk1OC/nhwA2kPwFyedSrn0vyXsqcw+ldtA3IZH8dROAowD08lY+AP8BcDMA77O6FsBSAHuFfX0/bxLsBuAqAIebmQe/jgDqZqk8aa9pZheR7AvgR2b2um8g2RXAkwC+BWAsgJ+FQNfdzLaE4wcC+CaALwDsAeC3JPcwMw98/rfpAgCnZansUoOpRiaSvy4E8DszW2lmnwO4FcBFYdtWAPsA2M/MtprZWx5RAGwH4LW27iTrm9kiM1tQxjWuCzWmaAHgNaTSlHbNdL4L4BUzG+37AvgzgN0AHJO0z71mtsTMvjKz5QDGATgvbBvgAc7MplTwnkktpEAmkr/aAlic9H5xWOf+BGA+gFEkF5K8wVeama+7xms3AFaSHEYycUw6fzazPRILgEPL2DftNTMpu5ntALAEQLukffx9sn8C+H547T+9yVKkXApkIvnrU6/9JL3fN6zzwLDOzK41s/0BnAXg54m+MDN7wsz6hGO9xnRHNgpT1jXDdUotO0kC6ABgWfIpU4550QMpyR4AzgAwNBvllppPgUwkP9Qn2ShpqRf6mG4muZcPtADwGwD/9p1JnkGycwgQhaFJcYf3kZE8MQwK2QTgK1+fjQKWds2weQUAD3AJT3v/lwc6b+IM/WubAbxT2vnNzMv7LIAnAEw0s0+yUW6p+RTIRPLDiBB0Eos3Dfpowcmh32o6gKlhnesCwAdWrAfwLoAHzGxM6B+7PQyg+AxAawA3ZqmMpV3T/TEEXe9ru87M5obmwftCWc70JWmgR2m8efEQNStKRVCJNUUkX5D05tM5APY2s7W5Lo/Eg2pkIpIXwnNwPwcwTEFMKkLPkYlIzpFsEvrZFoeh9yIZU9OiiIjEmpoWRUQk1tS0mAOtWrWyjh195iAREcnElClTfKaXxPRoJSiQ5YAHscmTfVS1iIhkgmTyLDclqGlRRERiTYFMRERiTYFMRERiTYFMRERiTYFMRERiTYFMRERiTYFMRERiTc+RZXeuuAcAeJqKsWampIAxMvWTL9GwXh0c3LZ5rosiIvlUIyP5GElPtz6jjH0WkZxOchrJ6Clhkh1IjiE5i+RMklcn7V/Wtp3Ole2ykxxAci7J+Smp3s/xpIBmdnnInisxcs4D7+Cb947HvBXrMHbuylwXR0TyqGnx8Qxnsu5nZr3MrCC83+YZZc2sO4CjAFxJsnsG29KdqxjJ1iSbpazrnGnZSdYFcD+A0wD4NQcmXbs9gCXhtWfOlRjq/9dx+OE/JuW6GCKSL4HMzMYBWL0Lxy03s6nh9ToAswG0K29bBo4H8GJIA++B6fKQwTbTsh8BYL6ZLQyZbocBODtsWxqCmVPfo4hINcmHP7ieR2YUySkkB6VuJOmz6/YGMCGDbWWey8yeATASwFMkLwRwKYDzKlDWdkm1rkTwSgTR5wGcS/JBAMPTHUzyTJJDCgsLK3BJERHJ98EefcxsmTf7ARhNck6oDfkf/qYAngNwTWrG2FK2lXquBDO7k6TXpDzgHGBm67PxIcxsA4BLytnHA9zwgoICrwmKiEhNqJF54Ak/vYf9hdB854GqfghUQ83MazvFSttW2rlSju0LoEfYfksFi+vn75D03psSo2uKiEgtDGQ+ZD0x+CIMX+8PYAZJAnjU+7/M7K6UY9JuK+1cKcd6M+SQ0K/ltaeWJAdXoMg+CqALyU4kGwC4AMBLlb8Tkkvbtu9Iu37ztu3YWso2Eak9w++fBPAugG4kl5K8LKwfQbItgDYAxpP8AMBEAK+Y2WsAjgVwEYATw1B6X04Ppy1tW2nnStYYwPlmtsDM/C/UxQAWZ1p2M/MRk1eFfjYfZPK0mc2synsoVe+Xz01Pu77bza/hpL+8We3lEZE86iMzs4GlrE8EJdczzfbxHktKObbUbenOlXLs2ynvtwJ4pIJlHwHAF6khnpvqY3ZK+nTNV9HPT1ZvzEGJRCRWfWQi+ej4P43JdRFEJEMKZCJpbN3uT3KISBwokImISKwpkImUY/1mH+MjIvlKgUykHC9/8GmuiyAiZVAgEynHWx99kesiiEgZFMhEyvHK9OVYs9HniBaRfKRAJpIBjWIUyV8KZCIiEmsKZCIiEmsKZCIiEmsKZCIiEmsKZCIZiJIHiUheUiATEZFYUyATycB7C1fluggiUgoFMpEM/PYl5U8VyVcKZCIZ+GK9ZvYQyVcKZCIiEmsKZCIiEmv1cl2AmoJkEwAPAPA2qLFmNjTXZRIRqQ1yViMj+RjJlSRnlLHPIpLTSU4jOTms60ByDMlZJGeSvDpp/1K3ZbN8JAeQnEtyPskbwupzADxrZpcDOGtXrysiIvFpWnwcwIAM9utnZr3MrCC893S915pZdwBHAbiSZPcMtkVItibZLGVd50zLR7IugPsBnAbAzz0wXKM9gCVht+2Z3gQREYlpIDOzcQBW78Jxy81sani9DsBsAO3K25bkeAAvkmzob0h6Deq+CpTvCADzzWyhmXkz4jAAZwNYGoJZqfeV5JkkhxQWFlb0Y4uISEwHe3gSqFEkp5AclLqRZEcAvQFMyHSbmT0DYCSAp0heCOBSAOdVoEztkmpeCAHM1z0P4FySDwIYnvbDmA03s0HNmzevwOVERCTOgz36mNkybw4EMJrknFBT8kDVFMBzAK4xs7XJB5W1zZnZnSS9JuVB5wAzW1/ZgprZBgCXVPY8IiJSg2pkHsTCz5UAXgjNeh6o6odANdTMvCZUrKxtSfv0BdAjnPOWChbLy9Qh6b03J0blFBGR6lcnn4ezJwZlhKHt/QHMIKN5yB/1/i8zuyvlmFK3Je3jzY1DQr+W16BakhxcgaJNAtCFZCeSDQBcAOClyn5eERGJ3/D7JwG8C6AbyaUkLwvrR5BsC6ANgPEkPwAwEcArZvYagGMBXATgxDAs35fTw2nL2pbQGMD5ZrbAzHYAuBjA4kzLZ2Y+MvKq0M/mg0meNjNNxCciUtv6yMxsYCnrkwNPzzTbx3ucKeXYUrcl7fN2yvutAB7JtHxh2wgAvoiISI7lbdOiiIhIJhTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1hTIREQk1urlugA1BckmAB4AsAXAWDMbmusyiYjUBlVaIyP5GMmVJGeUsc8iktNJTiM5OazrQHIMyVkkZ5K8OpPzpjtXtstOcgDJuSTnk7whadM5AJ41s8sBnFWZa4uISP40LT4OYEAG+/Uzs15mVhDebwNwrZl1B3AUgCtJds/wvKnnKkayNclmKes6Z1p2knUB3A/gNABenoFJ5WoPYEl4vT2DzywiIvkeyMxsHIDVu3DccjObGl6vAzAbQLvKnhfA8QBeJNnQ35D02tN9FSj7EQDmm9lCM/MmxGEAzg7bloZgVup9JXkmySGFhYW7UHQREcnXwR4GYBTJKSQHpW4k2RFAbwATKnsuM3sGwEgAT5G8EMClAM6rQFnbJdW6EsErEWCfB3AuyQcBDE9bOLPhZjaoefPmFbikiIjk+2CPPma2zJv9AIwmOSfUhjyINQXwHIBrzGxtZc6VYGZ3kvSalAecA8xsfTY+hJltAHBJNs4lIiIxqpF54Ak/VwJ4ITTfeRCrH4LYUDN7vjLnSkayL4AeYfstFSyun79D0ntvSoyuKSIitTCQ+ZD1xOCLMHy9P4AZJAngUe8bM7O7KnOulH28iXJI6Nfy2lNLkoMrUORJALqQ7ESyAYALALxUwY8tIiIxGn7/JIB3AXQjuZTkZWH9CJJtAbQBMJ7kBwAmAnjFzF4DcCyAiwCcGIbS+3J6Oect7VzJGgM438wWmNkOABcDWJxp2c3MR1NeFfrZfADK02Y2syrvoYiI5LCPzMwGlrK+OCgB6Jlm+3iPJRU9b7pzpRz3dsr7rQAeqcg1zGwEAF9ERCQP5LyPTEREpDIUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNYUyEREJNbq5boANQXJJgAeALAFwFgzG5rrMomI1AY5q5GRfIzkSpIzythnEcnpJKeRnBzWdSA5huQskjNJXl3R81a2fCQHkJxLcj7JG8LqcwA8a2aXAzirMtcWEZF4NC0+DmBABvv1M7NeZlYQ3m8DcK2ZdQdwFIArSXbP9LwkW5NslrKuc6blI1kXwP0ATgPg1x0Yrt8ewJKw2/YMPpeIiMQ5kJnZOACrd+G45WY2NbxeB2A2gHYVOO/xAF4k2dDfkPQa1H0VKN8RAOab2UIz82bEYQDOBrA0BLNS7yvJM0kOKSwsrOjHFhGRmA72MACjSE4hOSh1I8mOAHoDmJDxCc2eATASwFMkLwRwKYDzKlCmdkk1L4QA5uueB3AuyQcBDC/l2sPNbFDz5s0rcDkREYnzYI8+ZrbMmwMBjCY5J9SUPIg1BfAcgGvMbG1FTmpmd5L0mpQHnQPMbH1lC2pmGwBcUtnziIhIFdTIfEQeyWhfkl1JnkWyPqqYB7HwcyWAF0KzHsK1PYgNNTOvCVUIyb4AeoRz3lLBw71MHZLee3NiVE4REcnfpkWvBTUi6U1oowBcFAZDVJkQPJslDW3vD2AGSQJ41PvGzOyuXTivN0UOCf1aXoNqSXJwBU4xCUAXkp1INgBwAYCXKloOERGp3kBGM9sYhpg/YGbep3RwZS5M8kkA7wLoRnIpycvC+hEk2wJoA2A8yQ8ATATwipm9BuDYEEhPDMPyfTm9vPMmaQzgfDNbYGY7AFwMYHGm5TMzHzV5Vehn84EmT5vZzMrcCxERqfo+Mq8IHQ3AB0ckAoMPQ99lZjawlPXFQQlAzzTbx3t5KnrepO1vp7zfCuCRipzHzEYA8EVERGJSI7sGwI3ep+S1D5L7AxhTxWUTERHJTo3MzN4E8Gaomnnw+8LMfprJsSIiIvkwavEJkruHQRc+ZZNPD/WLKi2ZiIhIFpsWu4dntb4F4FUAncKACxERkVgEsvrh2S0PZC+FARI+64aIiEgsAtnDABYB8KbFcST3A1Ch2TRERERyOdjjXgC+JCwm2a9KSiQiIlIFgz2ak7zLc4KF5S+hdiYiIhKLpsXHAHjKlPPD4s2K/6jisolUq6m/PiXXRRCRKpzZw2eIPzfp/a0+NdSuXFAkX+3ZxKfOFJGaWiP7imSfxBuSPt/hV1VXLBERkewGsisA3E9ykS8A/gbgxxkeKxIbI37qGX5EpCaOWvQZ6Hv67B7h/VqSPv/ih1VeQpFq1L1t9F9cRGpqhuiUTMw/B3B39oskNdENz32IYZOWFL+/54JeOLuXp7cTEamepsV0Sk2lIpIqOYi5q4dNw4/+Odm/HCFfzfrdqbkugohUcSDL379AEguvz16Bj1auR75q3KBCDRYiko+BjOQ6kmvTLP5MmWdxFqmU/n8dh23bd2Dh5+sxYvryXBdHRGKozK+cZtas+ooitVXnmzyhQpFXftoHB7dtXu1l6NK6afHrrm2aYt6K/K0pikhJajuRvLJh8/Zqv+YBezVB172//s721KCjsXj1xmovh4jsGgWyLAlJRx8AsAXAWDMbmusyxVHhV54hKLdaNGkQLSJS8wd7lIvkYyRXkpxRxj7+kPV0n/LKJyQO6zqQHEPSM1HPJHl1yjEDSM4lOZ/kDWWdK9tlL+3aAM4B8KyZXQ7grMpcuza7/P8m45wH3sYbs1fgr6PnYdPWqq+hadSSSLxVaSAD8DiAARns18/MeplZQXi/DcC1ZtYdwFEAriTZPQSSuj7LCIDT/PlVAAMT20o5VzGSrUmW6Pcj2TnTspdz7fYAEmPMq799rAaZ+skaXPbPybjnjY/w6xdn4LPCTfjXe4ur9JqZPEvS+Vcj8NEKH+ckIrUmkJnZOACrd+G45WY2Nbz2vxyzASSenj0CwHwzW2hm3ow3DMDZGZ76eAAvkmzob0h67em+CpS9rGsvDcGs1PtK8kySQwoLCzMsrjwzZSmO+uMbUUCbn4Oh+gOP6FD8etsOw50j5+Lxtz+u9nKISO5qZJm27IwiOYXkoNSNJDsC6A1gQljlAS356dqlSUGuzHOZ2TMARnp/PskLAVwK4LwKlLWsaz8P4FySDwIYnvaDmg03s0HNm1f/qLya4OS73sTImZ9V81VL1tVGz1qB3w6fheuf9VnbRCQf5MNgjz5mtsyb/fzvBMk5oTbkQczHRD8H4JqU6bEqfK4EM7uTpNekHgzpabLyNd/MNgC4JBvnktK9t3BVNBvIkZ1aVsuADJbS5vj05KW46Zvd0Xy3+lVeBhHJ8xqZB57wcyWAF0LznQex+iGIDTUzr+0k+P5ft/cUNectK+tcyUj69OY9wvZbKljcUq8t1eMfby/CFf+eipPuehMbNntXKnLWd/bAmPlVfn0RyfNA5kPWE4MvwvD1/gBmkNH34Ee9b8zM7ko5bJI/v0qyE0n/Sn4BgJdKO1fK9byJckjo1/LaU0uSgytQ5LTXzsa9kIpZvWELDr5lJP717iK8/OGnVXadOqVVyQCs2Vj0qMCXG7Zgy7YdVVYGEcnt8PsnAbwLoBvJpSQvC+tHkPQprtoAGE/SOxwm+sQOZvYaAE/ceRGAE8NQel9O92PNzL+GXxX6unwQyNNmNrOMcyVrDOB8M1tgZv6X52IAizMtexnXlhz59X9m4qon3seSKnqAuU4ZVbKnJi/BV1u2o/dto3HVE9HYpGLe/PnJKj1ULRL7PjIzG1jK+igoBT3TbB9fVquOmY3wHIgp6xamO1fKPm+nvPev1I9UsOw7XVtyr++dY9C5dVM8+oMC7NfSK+TZUdQ4ULqDflP0XWnUrBUl1j88biFuf3UOXrumLw7cWznORGp0H5lItvjw/OP/NDZn1/fmxfWbt0W1w0kfFz25sWT1Vzkrj0htkQ+jFkWyypv1lhduQts9dqv0ucqpkJXQ9eavJz/eM4yozOd8ayI1hWpkUuN0unEEjrn9v5gYakWVwV3MH+uDUdzj7yyKgpkvHW94Bf/37qJKl0lESlIgkxrr/Iffxa3DZ2LF2k27fI5996xcre6dBauiqbYSQfU3/4n/2CAPxj97alquiyFSTIFMavxzZ0f+4Q289MGnUa1o9vJMnqv/WpvdG1W6DHe//hG+O+S94vczlsV7ijIPxi+8r8cnJX+oj0xqhZ8++X60uGMOaIkfHtMx6kPr0a551vrIMnXGfePxxrXHY8yclRj8yuxopOVu9evimM6tsn8xkVpAgUxqHW/u88XNHVxecoYqiGQATvrLm8WvfaZ/9/L/9ik3sIrIztS0KNXqwKRMzPmg282vYeHnPk1m9dXIypspREQqRoFMqtWtZx2MOKnGOBY7PuDj+D+NyXUxRBTI4uSL9ZtR+FW8v7UfuX9LLLr9m9FywF5N0KlV9mbhqArlzexRVdZt2hoN13/4zQU7bZv72bqcPZ+WfF0f8LF41cbo/6VILimQxUjB4NfR63ejUFO8ce0JGHPdCfj5KV1zXRS8/OHytOubNaq+buSZnxZi8aqiZs4v1hc9h/bHV+fggiE+5WeRsXNX4tS7x+GZyZ4Kr/qNn/9F2v+Xf/vvR1HwFckFDfaIGf9C7N/UU13Xv2v08O31Aw7E9c9+WLz+gsM7YECPvaM/jKf12BtNGhb9k3uCyi6tm6Jdi93QsF5d5NJPT+qCu0bPQz46tH31Db7woOXLB7f0x6ikBKLvLVwdTU68W4O6xVmyZ3+2Npp13/Oh1SlrZuMs+7KUfrw/j5qHsXM/x7M/OabayiKSoEBWQ/gfEpccxNywSUuixV33TOlZjb2pL5cuOmq/qKnx9yNmY+v2/JnWaVdn9qiMnrfuXOseNesznN2rXfRFJvF8nC/p/u28Zjd18Ze46GhPrp5dZeWAm7z4y6xfTyQTCmQSmbdiHbq2yd2Iwtu+5blOgYuP7ogPlxViwcr1uLaMwFtdDPkRVK8eNg2frtmEf7+XNusQJi1ajfvHzMejPzgc37zXk0egSgJZeWHdWwtm3npqcc1fpDqoj0wi/f86rspyelWEN5P16rAHvt27He78zqFo2aQBfjngwFwXKy/c8docLFuz82z6337gbZz30LtR097Kdbs+HVcmMhn7MmScZ1QSqT762iQlcnqls1ezhrisTycc2WlPHNy2eTRKLRszy5cX0M4v6BAt7uC2u+PixzxfqqR6/5M1xa9XhUEi7lcvTMfgs3tg1vK11fqg9ecaxSjVTIEsRp694mh856F3cdPpB+Hy4/bPyjlXrd+Mwwa/XuY+n6/bHCWJzKXjuu4V9QWlG+giJae/Snhiwido27xR1H/qz+9NWfwl/njOISWa/Tx/2qIvNmQc6DZt9cTqZVPqGqlualqMkYKOe2LObQPwo76dsnbOlk0b4h+XHI64GP/Lfrjngl54TqPjMjI9TFB8y0szo4mTn5z4SYntP/rnpCj4bd1efoByT08uGjgkkk9UI8sSkv5k7wOeKNgf9zGzoVVxnUb1sz9Uvl+31iVGvvk36q+2bsfTk5ZEk9pu25E/37Dbt2gcLe7flx2J7z86IddFymsjZ64o8d7/PR8b/zHeufGk6P3UxUXNkjsyrEVl9l9B86FILQ9kJB/zFhIAK82sRyn7+LjjdQC2A9hmZgUkvTPl/zzzRjTYDBhiZvdkuxwkfZZZP69HlL+b2e1h0zne+mdmw0k+BaBKAll1zWbRuEE9/PDYTtFSWUWJJYv6vbKpT5dWmDf4NNSrQ3y8akOJiXizpUHdmtdo8WnhJqzdtBW7N6qPLaEmdv9/5+Nnp3TN2UwmIpWRj7+ljwMob0py18/MenkQC+/9AZdrzaw7gKMAXEnSX5dAsjXJEuPMSXbOpBwkPXjdD+A0AH7ugUnXaA8g0e7iAVYC/+NYVQ/tNqhXJzr3AXs1jWqVf7848d8hO+rVwEDmDv3tqBKjVO/97/xocIgP5Nm+w9D1plfxy5RnEp3CnOSjvPstNbNxnil+F45bbmZTw2uvrc0G0C7NrscDeJFkQ39D8nIA92VYjiMAzDezhWbmTYjDAJwdti0NwSwv72ttcXL3Npj661Pwwv8cE42ylMxHqT45cUk03dR3Hnonqqk9NXkJ/jOtZALNTCps23fswDsLdp7KSqSqxPUPrjcdjiI5heSg1I0k/UnQ3gB26kAxs2e86wDAUyQvBHApgPMyvK4HxuTe7qVJwfJ5AOeSfBDA8HQHkzyT5JDCwnhnCM53ezZpgN77tsCwQV4xl8oM5/cHsZNHIWbSlfb05KX43iMT8N7CopxvIrWujyxDfcxsmTcTAhhNck6oQXmwaArgOQDXmFnavPZmdidJr0150DnAzIomsKsEM/PZXi8pZx8PcMMLCgq8FijV0KSZGMSybfsOdL7p1VwXKZY63TgC3ffZPXoezed2zJQ/tiFSHWJZI/MgFn6u9GwSocnP/3DVD0FsqJl5DSktkn0B9AjH3lKBS/t1i57QLeJNiSXbXiQveV/Xwj+cjnduOFEzhewCD2KuImmEfKJj/wKRiWlL1uDTNLOWiNTIQObD3BODNcKQ9/4AZrBouNWj3jdmZneVcbw3OQ4JfVteg2pJcnCGl58EoAvJTiQb+OTyAF7K2oeTKuWDQnxGkp+ccEBUU5t400k4odteeOTiAky5+eRcF6/Guf65D6Na8JqNW6KHrjdu2YZNW7fjxfeX4a2PPo8exvZ8ayvWbsK37n8bx9z+31wXWWKK+fYUPsknAZwAoBUAfwjmFjN7lOQIf37TH6UKNalE0+gTZvZ7kn0AvOXPgPrjLmH7r8xsRMr5jwWw1symJ9Xifmhmj2RYjtMB3B2G3z/m167oZywoKLDJkydX4i5JdVKzZPb4PJpe+3IdWzbGolUb0XvfPYr75XKdhUHyl4+JSBqlnt+BrDZQIIufn/x7Cl6d8XWOMKka6QKZ19h8ObT9Hjkpk+R/IItd06JILvz5vJ5RE6RULZ8YesDd47D0y43R69UbtuCEP43FWX97O+0cjq/PWpEXWRskt1QjywHVyOLr5Q8/xVVPvJ/rYtRK3+rVFt8/aj8s/HwDzj+8aMyVTyLdsF4dzB3scxQUOeaPb+DiYzriiuMPyGFpJdtUIxPJkjMObYsLwh9RqV4vTvs0yv7gg0i2bPt6NOTmpNeJKbg8W0NV52aT/BHX58hEcuYP3z4ETRvWw6Dj9scRf3gj18WplX7/yizsv5c/Mlpk/sr10XB/70tLmLBwNc7s2TZHJZTqpKbFHFDTYs1x6/CZ+HLDFkz4eDWWF6oGkG++W9AB5xW0R5fWzdC8cf0o/16zRvUxedHqKD/bVSd21kTJMaFRi3lGgaxmWvD5+ugP5B9GzKnQg8NSPTyPnU+51WHP3bBkddHD1y0a18dJB7WJBvNIflMgyzMKZDWf9+F4M1fqxLySn356Upco/957vyrK05bOuQ++E/WPnlegPtJc0GAPkWrm6WU67FmUAFTy371vfITP1m6KRkH6M4Nj5qzEhX9/L5p9JMGbIn+RJrWN5J4CmYhIEn/w/ZLHJ+Ht+avQ45aRmJAyi/8pd72JYRM/KbHu4y82RCMl1cKVGwpkIlXo7u/2ynURpJK+O+S9qKaW8NHK9bjh+aIkpL548Lrs8Ul46M0F+CTl4WxPUPqjf6oboapp+L1IFfpW73Y4uO3u0Yi51s0aRYNAEqlQpi8txJl/G5/rIsou8iSkzvvNFn7hWZyAdZu2RclIt243/OPtj6MEpa/P9qlai6xcuwmPvv0xzjikLT5auQ7f6tWuyrKn1yYKZCJVrEubKFlDJDmf1yHtm+eoRJJNwyZ9nWv3jPvK/mJy6t3j8OXGrXj4zYXRe6/RDTpOM5BUlpoWRfLAE5cfWfz65m8ehJ4dNEFuTfLHEbPx/b9PiIJYajZtr5knm7GsMJpj0ke9epPm05OTk9JLOhp+nwMafi8JPjluvTp1sHfzRrj79XnYuGU7fnX6QdG25H4Zqdke+v43cNA+u2O/lk2if3d/1u2Ocw/F9x6ZgKP23xPDBh2N2o5lDL9X06JIDrVv8fUQ/WtO7rpTShMfBg4Cm7fuiILe4Fdm56CUUtWu+PfU6GfBfi2in/7AdmIOye07yq9sTFi4KkoaW1sf+VCNLAdUI5PKUm2tdvnLeT2jhKTXndqtRD9r6v+HRTU4MalqZCI1cFi/fwNvu0cj9LlDs4fUdNc+80H089kpS3Fs55Z4ffbK4m37t2qC2k41shxQjUyqwmeFm6LmR091IrXbs1ccjUsfn4R7LuiNfge23mn75m3bsfarbWjZpEH0SEiLJg2i/z+tmzXM28cBNEWVSC3gA0YKOu5ZYpLchCv7ZXeI917NGuK6/l3xx3MOyep5JTu+89C7WLtpWzRDyV9Hz4tmHUmeyPrH/5qCw3//On7z0gz0vm10NP3WUX98Aw++uQBxpBpZlpD0+v0DPl8sgLFmNrS0fVUjk6o0cuZn6NamGTq2aoJNW7dH6xrVr4vOvxqBbRkMHMjEAXs1wRvXnhC9XvTFBqzasCWaVFfy33X9u+LPo+aVWFevDov/b3i+vV+9MB0f/rY/dm+0c39crauRkXyM5EqSM8rYZxHJ6SSnkZycybEkr/b1JGeSvKa8c2Wz7CQHkJxLcj7JG5I2neM1ejO7HMBZlbm2SGWcevDeURBLBDBf3OzbBuD5/zkmGhAw57YB+N3ZB+/yNeok5fDyax22X4uoWUry359TgphL/oLjQcwNfnnWTnNHHnv7f3HILSOxbE1RGpx8UdVNi48DGJDBfv3MrFdKtE17LMkeADxYHAHAkwidQbJzOedKHNuaZLOUdZ0zLTtJ/4twP4DTAHQHMJCk/3TtfdRseF30NVgkj9SvWwff2LdoeLcHt4uP7lhilNvEm0pPYZLqlO5tdlp3aZ9OWSqp5IOnJy9FpxtH4LDbRqPbza9GTZQewNZt3hYFtH+/tzjKyp1QuHFrzvLwVWkgM7NxAFZn+Vh/WnSCmW00M8+x8GaoDWXieAAvkoy+OpL0gHhfBa7vwXO+mS00M29CHAbg7LBtaQhmpd5XkmeSHFJYWPJJfpFc2qNxffz8lK7RXJDzBp+GBy/8Bt698cSoialvl1Zpj/nhMR13Wve9I/ethtJKdVu1YUv0TNs9b3xUYv3NL87AQb95DX8eORePjv8YPX83Cj1vHVU8O8nQCYurrYz5MPze666jSPrPh81sSDn7e1Pf70m2BOD129MBTM7kXGb2DEn/2vgUyWf8S6R/uaxAWdsl1boSwSsxt9DzAP5G0r/iDk/7Qc18/fCCggIPoCJ5Ydpv+pfIo3baIfsUByZffKBAm90bRlMpjZm7EmOv6xdNgpyqWcN8+HMi1e1vY+aXeP/M5CXFedsuPHK/ailDPvzP62Nmy7zZD8BoknNCbSgtM5tN8g4PWAB8yulpSU155Z7LzO4k6TWpB73P2szWZ+NDmJmX5ZJsnEskn9xw2oEZ7UcS536jPZ6buhRP//honP+wHgOojX6RlHzUH9T+2cldcc432uGCIe9F84gmvihlU86H33vgCT/9Cb8XQvNdecc8amaHmdlxAL4EMC/Tc5HsC6BH2H5LBYvr50/Oc+5NidE1RQT4y/k9o363Izp9/RhAj3a757RMklt/fX0e+t45Jupf+8nQoqm4alQg8yHricEXYfi6t3HMyOC46Ak/kvuG/rEnMjkXyd4AhoR+La89tSQ5uAJFnuRZObx5kmQDT0UE4KWKf3KRmu+kA1tj3z0b4+X/7YsBB+8drfNv5j85QWlLJLuqevj9kwC8faEbyaUkLwvrR5BsC8CHPo0n6fOvTATwipm9VtaxwXMkZ4W+qCvNbE1Z50riM2qeb2YLzMxn5LwYQNoeyXTXD4NLrvJHdXw0sw/sMbOZVXkPReLq0R8ejnHX94teP3DhN3D9gG743dk98MsBB+Ksnv7r//XD1e4Xp3bLWVkl3vRAdA7ogWgR4OMvNmDs3JX47uEd8MW6Ldi3ZcmZ2zUxcs20aBcnNtakwSKSdzq1aoJOrYqePdu35c5/ij64pT9Gz1qBzq2bolPLJtFIyW3bd+Cb947H3BXron1GXnNclHVZajcFMhHJS56u5DuHJR7NLFKvbh2M/NlxmLxodZSnq9vezfDNQ/fBKx8uj0ZMntK9dXFuL6k9FMhEJHaSJ0e+7ewe0fRYnlnbZy+ZdNPJaNG4Pjrf9Gq0/bEfFmCPxg0wYeFq3PHanByWWpx3Z/mjGtmkPrIcUB+ZSG6p/y13Fv7h9F1KFaM+MhGRJDNvPRVeKVheuAk3vTAdA4/YF1cPm1bcN+d53bwvTrKvKqpOOX8gWkSkujVpWA+NG9TDAXs1xbBBR+PsXj77HNCrwx5R39zBbZtH73/Up1OUJWDBH3wmPMmGqmgFVI1MRATAW9f3Q8umPs9B+mHinnXZswb0aNc8yvnmySkTPC3Ogb9OfWxV0slSSrwSFMhERHzuuT1LPsdW1gATz/nmgW7MnJXounczNKhbB11aN8XVJ3fBGYe2VR9cGawKGhcVyEREdlG/A6PZ8iKjf+5ZoorM/t2AqJ+tfYvG+GDpmmhU5e9enoX7BvbGIb8tSnUy5KLDcHjHPdH7ttGoTepmecSi06jFHNCoRRFJeOH9pfjZUz6z3tcObd8clx7bCdc8VTQApSZZpJk9RERqlm/3bh8tn675Cm/O+xwdWjTGYfu1wG4N6kZJTz3r8uJVG3Fmz7bo9+ex0TFNGtTFhqTszLWdApmISB5ou8du0WMAyU7o9nXTpfM8b3s2qY/OrZvhwr+/h8/XbcY/LjkCx97+X9RmCmQiIjGRnOdt6I+OKn796tV9MWL6cqxcuxl3fOdQbNyyDWPnfo7/qaL8X/lGgUxEJOYO2mf3aEnwZ+ROP2QffPCb/mjUoA4a1qsbrS8YPBqX990fHVs1KfH4QNwpkImI1FDNG9cv8X7yzadEP32Q38MXHYajD2iJ+SvX4xv7tsBnhZswcdHqqP/tsn/GazCaApmISC1DMnoWznkQc3s3b1Sc8NSn6WpYrw7Gzfscx3ZuhQ+WrMHtr83BH759CJ6fugyPvf1xNLKyze6NolQ7uabh9zmg4fciUlNs3rYdVz3xPn56Yhe03r0h3v9kDa74d/pmyx8cvR9uPbtH1offK5DlgAKZiNRkT09eEiVObdqwHt766PPombhtOyya4mtX6TmyakCyCYAHAGwBMNbMhua6TCIiuXB+QYfi14lBKGG8SZXI2ez3JB8juZLkjDL2WURyOslpJCdncizJq309yZkkr6mK8pEcQHIuyfkkbwirz/F5Rc3scgBn7ep1RUQkPmlcHgcwIIP9+plZr5QqZdpjSXrjqweSIwD0BHAGyc4p+7Qm2SxlXYl9yrmGf6+4H8BpALoDGEjSf3pO9iVhNz1yLyJS0wOZmY0DsDrLxx4EYIKZbTSzbQDeDDWlZD6z54skG/obkh747qvANTxIzjezhWbmzYjDAJwNYGkIZk553kREqkm+/8H1kSijvJOP5KAM9vdmwL4kW5L0nAyeDa9DSoB6BsBIAE+RvBDApQDOq0CZ2iXVvBACmK97HsC5JB8EMDzdgSTPJDmksLCwApcTEZGy5Ptgjz5mtsybAz1LAsk5oaaUlpnNJnmHBz8AGwBMS9fMZ2Z3kvSalAedA8xsfWULamZ+vUvK2ccD3PCCggKvBYqISE2vkXkQCz9XeraD0KxX3jGPmtlhZnYcgC8BzEvdh2RfAD3COW+pYLGWpdTyvDkxKqeIiFS/Ovk8nD0xKCMMbe8fmg7LOy6aLprkvqF/7ImU7b09p13o1/IalDdDDq5A0SYB6EKyE0nPi34BgJd24SOKiEjMh98/CeBdAN1ILiV5WVg/gqTPk9IGwHiSnnFuIoBXzOy1so4NniM5K/RTXWlma1Iu7X1n55vZAjPbAeBiAIszLV8YRHJV6Geb7c/+mdnMKr5dIiJSCs3skQMkP08XPDPUCsAXWS5SnOl+lKT7UZLuR825H/uZ2V7pNiiQxYw/GF7aNC21ke5HSbofJel+1I77kbd9ZCIiIplQIBMRkVhTIIsfH3EpX9P9KEn3oyTdj1pwP9RHJiIisaYamYiIxJoCmYiIxJoCWUyUkgMtttLleyO5J0mfU/Oj8LNFWO/uDZ/9Q5LfSDrmB2F/X36QtP6wkMtufjiWZV0j10h2IDnGH+YPufSurs33hGQjkhN9QoRwP24N631GnQnhMzwVZtfx9Q3D+/lhe8ekc90Y1vvvz6nl/U6Vdo1c8xRSJN8n+XJtvxc78T4yLfm9APAcaAsA7A/A/yP5bCfdY/6ZfC5M/+M7I2ndnQBuCK/9l+mO8NqzGLzqv1cAjgqpenz9ngAWhp8twusWYdvEsC/DsaeVdY1cLwD28fsRXjcLc4R2r633JJSxaXhd3z9fKPvTPi1cWP8QgJ+E1//j78NrnzbuqfC6e/h98bRNncLvUd2yfqdKu0auFwA/D1PuvVxWOVEL7sVO9ybXBdCSwT8ScLRPiZX0/kZfasDn6pgSyOb6H/SkP+xzw+uHPYFp6n6+zrclrY/2C9vmJK0v3q+0a+TbAuA/AE7RPbHEtHJTARwZZqWol/p7EaaMOzq8rhf2Y+rvSmK/0n6nwjFpr5Hje+CTk78B4EQPZGWVEzX8XqRb1LQYD6XlQKtp2pjZ8vD6szDfZlmfv6z1S9OsL+saeSM0BfUOtZBae09CU5qnYvLsF6NDrWFNmO809TMUf+6w3ZP+tdyF+9SyjGvk0t0Argfg88OinHK2q+H3YicKZJKXrOgroMX9GhVFsqlPfA3gGjNbW5vviZltN7NeoTbiKZwORC1E8gwP5mY2JddlyVcKZPFQW3KgrSC5T/jl3Sd8Ey/r85e1vn2a9WVdI+dI1g9BbKiZecZx1PZ74kIGizGhaWsPkvXSfIbizx22Nwewahfu06oyrpErxwI4i+QiAMNC8+I9tfRepKVAFg+1JQeaf6bEKLsfhH6ixPqLw0g97/AvDE1h3sbf30fZhZF2/UMbvm9b6/uGkXkXp5wr3TVyKpTzUU8NZGZ31fZ7QnIvknuE17uF/sLZIaB9p5T7kfgMvv2/oXbp6y8II/l8gEOXMOgl7e9UOKa0a+SEmXm/Vnsz6xjK6Z/twtp4L0qV6046LZktYZTavNBPcFMN+Dye783/uG4Nbe+XhTZ579D+CMDrPvIu7Ot/eO8Pn306gIKk81wKYH5YLkla7zN8zwjH/C1pFpu018j1AqBPaNL7EMC0sJxeW+8JgEMBvB/uh5f5N2H9/uGPr3+2Z3wEXljfKLyfH7bvn3Sum8JnnpsYqVnW71Rp18iHBcAJSaMWa/W9sKRFU1SJiEisqWlRRERiTYFMRERiTYFMRERiTYFMRERiTYFMRERiTYFMJMZIrg8/O5L8XpbP/auU9+9k8/wi2aJAJlIz+MOyFQpkSTM2lKZEIDOzY3apZCJVTIFMpGa4HUBfn2SX5M/ChLt/Ijkp5Cv7se9E8gSSb5H0WR5mhXUvkpwS8n4NCuv8fLuF8w1Nqf0xnHtGyG/23aRzjyX5LMk5flwi55lIVSrvG5mIxIPnEbvOzM4IQWVQmLbqcJ+SCMDbJEeFfT0PXA8z+zi8v9TMVoepoDzwPWdmN5C8Kkzam+ocAL6+J4BW4ZhxYZvP2n8wgE/9mmGewPHVcwuktlKNTKRm6h/mYpwW0sG0DHPruYlJQcz91DMxA3gvTB6b2K80Pp3Wk2F2+hUA3gRweNK5l5qZpxvxaxdnJxapKqqRidRM3qT3v2Y2ssRK0ufq25Dy/uSQiHGjNw2Gufp21eak19v1N0aqg2pkIjXDOgDNkt57APtJSA3jAasrySZpjvMUH1+GIOb5vnwm/YStieNTvAXgu6Efbi8Ax4WJZUVyQt+WRGoGnyV+e2gifDzkq/JmvalhwMXnAL6V5rjXAFxBcnaYEd2bFxOG+HlJTg1pQxJeCLnB/Fo+6/j1ZvZZCIQi1U6z34uISKypaVFERGJNgUxERGJNgUxERGJNgUxERGJNgUxERGJNgUxERGJNgUxERBBn/w8yPP7ZnNJoJgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_iter = 100000\n",
    "# if loss history exists, append to it\n",
    "if 'loss_history' not in locals():\n",
    "    loss_history = []\n",
    "\n",
    "target_loss = 1.5179\n",
    "print_every = 100\n",
    "if 'min_loss_found' not in locals():\n",
    "    min_loss_found = float('inf')\n",
    "\n",
    "if 'best_height_params' not in locals():\n",
    "    best_height_params = height_params.data.clone()\n",
    "\n",
    "for i in range(max_iter):\n",
    "    # Compute loss and gradient\n",
    "    height_params.grad = None\n",
    "    loss = loss_fn()\n",
    "    loss.backward()\n",
    "\n",
    "    grad = height_params.grad.data\n",
    "    grad_norm_squared = torch.norm(grad)**2\n",
    "    \n",
    "    step_size = (loss.item() - target_loss) / grad_norm_squared\n",
    "    height_params.data -= step_size * (grad + torch.randn_like(grad) * 0.000)\n",
    "\n",
    "    # Project onto the simplex\n",
    "    with torch.no_grad():\n",
    "        height_params.data = projection_simplex_pytorch(height_params.data, 2*P_val)\n",
    "\n",
    "    loss_history.append(loss.item())        \n",
    "    if i % print_every == 0:\n",
    "        print(f\"Iteration {i}: loss = {loss.item():.6f}, step_size = {step_size:.6f}, min_loss_found = {min_loss_found:.6f}\",)\n",
    "\n",
    "    if loss.item() < min_loss_found:\n",
    "        min_loss_found = loss.item()\n",
    "        best_height_params = height_params.data.clone()\n",
    "\n",
    "print(\"Final loss:\", loss.item())\n",
    "\n",
    "# semilogy plot of loss history\n",
    "plt.semilogy(loss_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
